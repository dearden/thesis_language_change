{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_change_methods\n",
    "from language_change_methods.features import function_words\n",
    "from language_change_methods.utility_functions import get_data_windows, get_time_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "sys.path.insert(1, \"../utilities\")\n",
    "\n",
    "from settings import DB_FP\n",
    "\n",
    "out_dir = \"./Graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_fp = \"../resources/key-dates.csv\"\n",
    "\n",
    "key_dates = pd.read_csv(dates_fp, delimiter=\"\\t\")\n",
    "\n",
    "convert_to_date = lambda x: datetime.strptime(x, \"%d-%m-%Y\")\n",
    "key_dates[\"date\"] = key_dates[\"date\"].apply(convert_to_date)\n",
    "key_dates.set_index(\"date\", inplace=True)\n",
    "key_dates = key_dates.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_all_posts =\"\"\"\n",
    "SELECT c.uid, m.name, m.PimsId, p.party, d.date, c.body, c.topic, c.section, s.tmay_deal, s.benn_act, s.ref_stance, s.constituency_leave, c.usas_file\n",
    "FROM contributions as c\n",
    "INNER JOIN members as m\n",
    "ON m.PimsId = c.member\n",
    "INNER JOIN debates as d\n",
    "ON d.uid = c.debate\n",
    "INNER JOIN member_party as p\n",
    "ON p.PimsId = m.PimsId\n",
    "INNER JOIN member_stances as s\n",
    "ON s.PimsId = m.PimsId\n",
    "WHERE (d.date BETWEEN date(\"2015-05-01\") AND date(\"2019-09-10\"))\n",
    "AND (((d.date BETWEEN p.start AND p.end) AND NOT (p.end IS NULL))\n",
    "OR ((d.date >= p.start) AND (p.end IS NULL)));\"\"\".strip()\n",
    "\n",
    "# regex for identifying EU/brexit mentions\n",
    "eu_regex = r'\\b(EU|[Ee]uropean [Uu]nion|[Bb]rexit)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(DB_FP)\n",
    "curs = conn.cursor()\n",
    "\n",
    "# Gets all the contributions and creates a nice dataframe\n",
    "all_contributions = pd.read_sql_query(sql_get_all_posts, conn)\n",
    "all_contributions.columns = ['uid', 'name', 'PimsId', 'party', 'date', 'text', 'topic', 'section', 'tmay_deal', 'benn_act', 'ref_stance', 'constituency_leave', 'usas_file']\n",
    "all_contributions.set_index(\"uid\", inplace=True)\n",
    "convert_to_date = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "all_contributions['date'] = all_contributions['date'].apply(convert_to_date)\n",
    "all_contributions.sort_values(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from language_change_methods.utility_functions import clean_text, spacy_tokenise# spacy_pos\n",
    "# from text_processing import ucrel_tokenise\n",
    "import nltk\n",
    "import regex as re    \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', parser=False, entity=False, matcher=False, add_vectors=False)\n",
    "\n",
    "def tokenise(text):\n",
    "    cleaned = clean_text(text)\n",
    "    cleaned = re.sub(r\"(\\p{P})\\p{P}*\", r\"\\1 \", cleaned)\n",
    "    tokens = spacy_tokenise(cleaned)\n",
    "    return tokens\n",
    "\n",
    "all_toks =  all_contributions[\"text\"].apply(tokenise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_vocab_and_vectors(model, n=10000):\n",
    "    \"\"\"\n",
    "    Gets the top n words from the model's vocabulary and the vectors of these words.\n",
    "    \"\"\"\n",
    "    top_vocab = sorted(model.wv.vocab.keys(), key=lambda x: model.wv.vocab[x].count, reverse=True)[:n]\n",
    "    top_vectors = np.array([model.wv[t] for t in top_vocab])\n",
    "    return top_vocab, top_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_vectors(model, voc_fp, vec_fp):\n",
    "    vocs = sorted(model.wv.vocab.keys(), key=lambda x: model.wv.vocab[x].count, reverse=True)[:10000]\n",
    "    vecs = np.array([model.wv[t] for t in vocs])\n",
    "    \n",
    "    with open(voc_fp, 'w') as voc_file:\n",
    "        json.dump(vocs, voc_file)\n",
    "        \n",
    "    np.save(vec_fp, vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# suppress some deprecation warning..\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR = \"./Models\"\n",
    "LOAD = False\n",
    "# LOAD = os.path.exists('word_vectors/static/word_vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model on all contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "curr_dir = os.path.join(EMB_DIR, \"static\")\n",
    "check_dir(curr_dir)\n",
    "\n",
    "if LOAD:\n",
    "    print(\"Loading Model\")\n",
    "#     model = Word2Vec.load('word_vectors/w2v_all_contributions_static.npy')\n",
    "    with open(os.path.join(curr_dir, 'vocab_all.json')) as voc_file:\n",
    "        vocs = json.load(voc_file)\n",
    "    vecs = np.load(os.path.join(curr_dir, 'word_vectors_all.npy'))\n",
    "else:\n",
    "    # training the model\n",
    "    print(\"Training model\")\n",
    "    model = Word2Vec(all_toks, size=300)\n",
    "    # model.save('word_vectors/w2v_all_contributions_static.bin')\n",
    "    \n",
    "    save_word_vectors(model, \n",
    "                      os.path.join(curr_dir, 'vocab_all.json'), \n",
    "                      os.path.join(curr_dir, 'word_vectors_all.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10000 = sorted(model.wv.vocab.keys(), key=lambda x: model.wv.vocab[x].count, reverse=True)[:10000]\n",
    "top_vectors = np.array([model.wv[t] for t in t10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 38465\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size: {}\".format(len(model.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           4796229\n",
      "       the 2803248\n",
      "         , 1860753\n",
      "         . 1805540\n",
      "        to 1448366\n",
      "        of 1145774\n",
      "      that 1130001\n",
      "       and 1095262\n",
      "        in 839869\n",
      "         a 724597\n"
     ]
    }
   ],
   "source": [
    "def show_top_token_freq(model,topn):\n",
    "    for w, v in sorted(list(model.wv.vocab.items()), key=lambda x:x[1], reverse=True)[:topn]:\n",
    "        if topn<=20:\n",
    "            print(f\"{w:>10s} {v.count:5d}\")\n",
    "        else:\n",
    "            print(f\"{w}({v.count}), \", end=\"\")\n",
    "            \n",
    "show_top_token_freq(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brexit:\n",
      "['mortem(0.49617)', 'mortems(0.48390)', 'exit(0.47262)', 'referendum(0.45965)', 'renegotiation(0.44157)', 'brexiteers(0.41249)', 'ttip(0.41093)', 'pre(0.39478)', 'negotiation(0.39092)', 'deal(0.38097)']\n",
      "--------------------\n",
      "eu:\n",
      "['eea(0.71330)', 'euratom(0.68788)', 'euNUMBER(0.68492)', 'european(0.67392)', 'eurozone(0.59399)', 'cfp(0.59027)', 'euro(0.56000)', 'europe(0.55436)', 'echr(0.55253)', 'efta(0.52765)']\n",
      "--------------------\n",
      "union:\n",
      "['superstate(0.57532)', 'pan-(0.55770)', 'union-(0.52502)', 'eu(0.50887)', 'convention(0.45355)', 'euratom(0.44337)', 'unionists(0.43717)', 'championship(0.43316)', 'jewry(0.42936)', 'unions(0.42411)']\n",
      "--------------------\n",
      "european:\n",
      "['eu(0.67392)', 'soviet(0.59859)', 'customs(0.55448)', 'cinematograph(0.54138)', 'subscriptions(0.53913)', 'euratom(0.50186)', 'eea(0.49706)', 'reps(0.49241)', 'euNUMBER(0.48421)', 'europe(0.48292)']\n",
      "--------------------\n",
      "europe:\n",
      "['world(0.60350)', 'continent(0.58500)', 'eu(0.55436)', 'balkans(0.54690)', 'globe(0.54588)', 'mediterranean(0.53646)', 'gulf(0.52849)', 'democracies(0.50161)', 'aegean(0.49395)', 'america(0.48898)']\n",
      "--------------------\n",
      "remainers:\n",
      "['brexiteers(0.51712)', 'eurosceptics(0.46149)', 'remoaners(0.44465)', 'patriotic(0.42410)', 'deluded(0.41061)', 'brexiteer(0.40970)', 'racists(0.40840)', 'msps(0.40718)', 'reversers(0.39651)', 'bedfellows(0.39614)']\n",
      "--------------------\n",
      "trade:\n",
      "['trading(0.54916)', 'tariff-(0.54036)', 'trades(0.46277)', 'subsidy-(0.45363)', 'barrier-(0.43894)', 'gluten-(0.43811)', 'nautilus(0.43027)', 'exports(0.42929)', 'japan(0.41942)', 'protectionist(0.41804)']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def get_word_similarity(model, word, topn=10):\n",
    "    if model.wv.__contains__(word):\n",
    "        vecs = [f\"{w}({v:.5f})\" for w, v in model.wv.most_similar(word)]\n",
    "        print(f\"{word}:\\n{vecs}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not found in this model\")\n",
    "    print(\"--\"*10)\n",
    "\n",
    "words = ['brexit', 'eu', 'union', 'european', 'europe', 'remainers', 'trade']\n",
    "\n",
    "for word in words:\n",
    "     get_word_similarity(model,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       remainer: 0.4696\n",
      "parliamentarian: 0.4682\n",
      "  devolutionist: 0.4459\n",
      "       advocate: 0.4218\n",
      "           scot: 0.4196\n",
      "      energetic: 0.4196\n",
      "        staunch: 0.4147\n",
      "     politician: 0.4118\n",
      "     campaigner: 0.4091\n",
      "    eurosceptic: 0.4071\n"
     ]
    }
   ],
   "source": [
    "result = model.wv.most_similar(positive=['remain', 'brexiteer'], negative=['leave'])\n",
    "for word, score in result:\n",
    "    print(f\"{word:>15s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(query : str,\n",
    "              embs: np.ndarray,\n",
    "              vocab: list,\n",
    "              K : int = 3) -> list:\n",
    "    sims = np.dot(embs[vocab.index(query),],embs.T)\n",
    "    output = []\n",
    "    for sim_idx in sims.argsort()[::-1][1:(1+K)]:\n",
    "        if sims[sim_idx] > 0:\n",
    "            output.append(vocab[sim_idx])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_changey_words_with_models(model1, model2, n=100, k=1000, top_n=None):\n",
    "    nn_scores = []\n",
    "    \n",
    "    top_vocab = sorted(model1.wv.vocab.keys(), key=lambda x: model1.wv.vocab[x].count, reverse=True)[:top_n]\n",
    "    \n",
    "    vocab1 = model1.wv.vocab\n",
    "    vocab2 = model2.wv.vocab\n",
    "    # Loop through all the words in the vocab\n",
    "    for w in vocab1:\n",
    "        if (w not in function_words \n",
    "                and w in vocab1 \n",
    "                and w in vocab2 \n",
    "                and vocab1[w].count > n \n",
    "                and vocab2[w].count > n \n",
    "                and w in top_vocab):\n",
    "            neighbours1 = set([x[0] for x in model1.wv.most_similar(w, topn=k)])\n",
    "            neighbours2 = set([x[0] for x in model2.wv.most_similar(w, topn=k)])\n",
    "            nn_scores.append((len(neighbours1.intersection(neighbours2)), w))\n",
    "            \n",
    "    nn_scores_sorted = sorted(nn_scores)\n",
    "    return nn_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_changey_words_with_vectors(vocab1, vocab2, vectors1, vectors2, n=20, k=1000):\n",
    "    nn_scores = []\n",
    "    # Loop through all the words in the vocab\n",
    "    for w in vocab1:\n",
    "        if w not in function_words and w in vocab1 and w in vocab2:\n",
    "            neighbours1 = set(neighbors(w, vectors1, vocab1, k))\n",
    "            neighbours2 = set(neighbors(w, vectors2, vocab2, k))\n",
    "            nn_scores.append((len(neighbours1.intersection(neighbours2)), w))\n",
    "            \n",
    "    nn_scores_sorted = sorted(nn_scores)\n",
    "    return nn_scores_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get neighbours of keywords for chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "election,vote,elections,brexit,leave,voted,votes,article,parliament,debate\n",
      "referendum,exit,deal,vote,eu,austerity,negotiations,outcome,what,union\n",
      "migration,asylum,fisheries,welfare,border,detention,sanctions,migrants,trade,borders\n",
      "stay,remain,referendum,lose,leaving,left,exit,leaves,vote,go\n"
     ]
    }
   ],
   "source": [
    "queries = [\"referendum\", \"brexit\", \"immigration\", \"leave\"]\n",
    "for query in queries:\n",
    "#     print(query)\n",
    "    print(\",\".join(neighbors(query, top_vectors, t10000, 10)))\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labour vs Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservatives = all_contributions.query(\"party == 'Conservative'\")\n",
    "labour = all_contributions.query(\"party == 'Labour'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Conservative model\n",
    "con_model = Word2Vec(all_toks.loc[conservatives.index], size=300)\n",
    "\n",
    "# Labour model\n",
    "lab_model = Word2Vec(all_toks.loc[labour.index], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ranked_words_models = get_most_changey_words_with_models(con_model, lab_model, n=10, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 'instantly'),\n",
       " (17, 'cogent'),\n",
       " (17, 'nudge'),\n",
       " (18, 'faraday'),\n",
       " (19, 'cse'),\n",
       " (21, 'bundle'),\n",
       " (21, 'ni'),\n",
       " (22, 'scales'),\n",
       " (23, 'abysmal'),\n",
       " (23, 'afloat'),\n",
       " (24, 'honours'),\n",
       " (25, 'lab'),\n",
       " (26, 'mustard'),\n",
       " (27, 'forensically'),\n",
       " (27, 'macroeconomic'),\n",
       " (27, 'thereafter'),\n",
       " (27, 'unskilled'),\n",
       " (29, 'costings'),\n",
       " (30, 'caseload'),\n",
       " (30, 'handover')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_words_models[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 63.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_con, vectors_con = get_top_vocab_and_vectors(con_model)\n",
    "vocab_lab, vectors_lab = get_top_vocab_and_vectors(lab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ranked_words_vectors = get_most_changey_words_with_vectors(vocab_con, vocab_lab, vectors_con, vectors_lab, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(152, 'mirrors'),\n",
       " (213, 'honours'),\n",
       " (221, 'presiding'),\n",
       " (254, 'inadvertently'),\n",
       " (256, 'thereafter'),\n",
       " (257, 'seemingly'),\n",
       " (260, 'harlow'),\n",
       " (265, 'redditch'),\n",
       " (267, 'moray'),\n",
       " (285, 'ideally'),\n",
       " (287, 'bypass'),\n",
       " (301, 'continually'),\n",
       " (305, 'promptly'),\n",
       " (311, 'deane'),\n",
       " (315, 'naturally'),\n",
       " (317, 'beforehand'),\n",
       " (321, 'speedily'),\n",
       " (323, 'alternatively'),\n",
       " (324, 'manual'),\n",
       " (329, 'sensibly')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_words_vectors[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Examples with Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mirrors',\n",
       " 'presiding',\n",
       " 'inadvertently',\n",
       " 'thereafter',\n",
       " 'seemingly',\n",
       " 'harlow',\n",
       " 'ideally',\n",
       " 'continually',\n",
       " 'naturally',\n",
       " 'alternatively']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in ranked_words_vectors if check_freq(w[1],con_model) and check_freq(w[1],lab_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mirrors\n",
      "Con: ['includes', 'under', 'allows', 'anti-', 'page', 'contains', 'covers', 'modern']\n",
      "Lab: ['tory', 'words', 'side', 'lines', 'tories', 'parties', 'benches', 'rhetoric']\n",
      "\n",
      "presiding\n",
      "Con: ['police', 'senior', 'officer', 'presiding', 'director', 'crown', 'prison', 'assembly']\n",
      "Lab: ['period', 'weekend', 'austerity', 'decades', 'presided', 'decade', 'presiding', 'half']\n",
      "\n",
      "inadvertently\n",
      "Con: ['harm', 'inadvertently', 'otherwise', 'damage', 'any', 'anything', 'unnecessary', 'anybody']\n",
      "Lab: ['commons', 'remind', 'statement', 'assure', 'sir', 'update', 'lords', 'sides']\n",
      "\n",
      "thereafter\n",
      "Con: ['after', 'soon', 'recess', 'until', 'period', 'ahead', 'next', 'shortly']\n",
      "Lab: ['after', 'post-', 'member', 'before', 'low-', 'allowance', 'result', 'during']\n",
      "\n",
      "seemingly\n",
      "Con: ['person', 'there', 'slightly', 'an', 'someone', 'woman', 'somebody', 'perfectly']\n",
      "Lab: ['failure', 'uncertainty', 'brexit', 'financial', 'budget', 'scale', 'rhetoric', 'caused']\n",
      "\n",
      "harlow\n",
      "Con: ['st', 'town', 'college', 'constituency', 'county', 'valley', 'mid', 'east']\n",
      "Lab: ['hon', 'sir', 'member', 'friend', 'lady', 'mrs', 'dr', 'gentleman']\n",
      "\n",
      "ideally\n",
      "Con: ['better', 'easier', 'where', 'best', 'easy', 'they', 'dangerous', 'otherwise']\n",
      "Lab: ['be', 'insert', 'page', 'which', 'co-', 'rather', 'better', 'high-']\n",
      "\n",
      "continually\n",
      "Con: ['carefully', 'forward', 'properly', 'constantly', 'determined', 'ensure', 'hard', 'how']\n",
      "Lab: ['glad', 'repeatedly', 'afraid', 'pleased', 'already', 'behind', 'down', 'failing']\n",
      "\n",
      "naturally\n",
      "Con: ['where', 'if', 'otherwise', 'frankly', 'sometimes', 'afraid', 'naturally', 'they']\n",
      "Lab: ['importantly', 'residents', 'businesses', 'thousands', 'concerned', 'many', 'chain', 'industries']\n",
      "\n",
      "alternatively\n",
      "Con: ['if', 'whether', 'otherwise', 'not', 'afford', 't', 'apply', 'whatever']\n",
      "Lab: ['rent', 'homes', 'vehicles', 'yes', 'cars', 'electric', 'not', 'diesel']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Con:\", neighbors(query, vectors_con, vocab_con, 8))\n",
    "    print(\"Lab:\", neighbors(query, vectors_lab, vocab_lab, 8))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thereafter',\n",
       " 'mirrors',\n",
       " 'presiding',\n",
       " 'nationwide',\n",
       " 'bogus',\n",
       " 'naturally',\n",
       " 'super-',\n",
       " 'winners',\n",
       " 'individually',\n",
       " 'latter']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in ranked_words_models if check_freq(w[1],con_model) and check_freq(w[1],lab_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thereafter\n",
      "Con: ['afterwards', 'recess', 'subsequent', 'commence', 'before', 'easter', 'purdah', 'sometime']\n",
      "Lab: ['regularise', 'wanstead', 'ewell', 'aunts', 'unpicked', 'widowers', 'alabed', 'miserly']\n",
      "\n",
      "mirrors\n",
      "Con: ['criminalises', 'replicates', 'streamlines', 'amends', 'repeals', 'simplifies', 'codifies', 'devolves']\n",
      "Lab: ['smoke', 'poisonous', 'ugly', 'vicious', 'insidious', 'nationalism', 'shirkers', 'clinging']\n",
      "\n",
      "presiding\n",
      "Con: ['commanding', 'warranted', 'certification', 'chief', 'pcc', 'pored', 'police', 'presided']\n",
      "Lab: ['presided', 'preside', 'glossed', 'roughshod', 'presides', 'hangs', 'pored', 'hanging']\n",
      "\n",
      "nationwide\n",
      "Con: ['comprising', 'segment', 'vertical', 'hyper-', 'rNUMBER', 'satellite', 'specification', 'geographic']\n",
      "Lab: ['unfilled', 'homicides', 'rotherham', 'comprises', 'apartment', 'haringey', 'micrograms', 'house-']\n",
      "\n",
      "bogus\n",
      "Con: ['unregistered', 'crowdfunding', 'converter', 'overcomplicated', 'sexualised', 'abusive', 'biosimilars', 'exhausting']\n",
      "Lab: ['congratulatory', 'congratulation', 'indulgent', 'defeating', 'harming', 'gendered', 'casual', 'exploitative']\n",
      "\n",
      "naturally\n",
      "Con: ['understandably', 'frankly', 'normally', 'hurt', 'inevitably', 'otherwise', 'confusing', 'sometimes']\n",
      "Lab: ['wager', 'electricians', 'debenhams', 'kirton', 'viewers', 'plantations', 'holidaymakers', 'upland']\n",
      "\n",
      "super-\n",
      "Con: ['weston-', 'mare', 'roxburgh', 'berwickshire', 'upon-', 'wyre', 'berwick-', 'selly']\n",
      "Lab: ['corporations', 'rich', 'giveaways', 'mega-', 'wealthy', 'sugary', 'asset-', 'greedy']\n",
      "\n",
      "winners\n",
      "Con: ['losers', 'nobel', 'rows', 'nominees', 'winner', 'prizes', 'strawberries', 'atherton']\n",
      "Lab: ['losers', 'productions', 'dirtiest', 'super-', 'primitive', 'surpluses', 'cables', 'reproduced']\n",
      "\n",
      "individually\n",
      "Con: ['kill', 'intimidate', 'individual', 'either', 'entertain', 'promptly', 'offend', 'practically']\n",
      "Lab: ['regulators', 'agendas', 'occupiers', 'counters', 'ipads', 'shower', 'partake', 'collectively']\n",
      "\n",
      "latter\n",
      "Con: ['focal', 'hinkley', 'pinch-', 'vantage', 'salient', 'moot', 'scoring', 'pinch']\n",
      "Lab: ['unthinkable', 'doctrine', 'untrue', 'valid', 'technically', 'harris', 'wilson', 'moot']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Con:\", [x[0] for x in con_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"Lab:\", [x[0] for x in lab_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EU vs Non-EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_functions' from '../utilities\\\\helper_functions.py'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import helper_functions\n",
    "reload(helper_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from helper_functions import split_corpus\n",
    "\n",
    "eu_mentions, non_eu_mentions = split_corpus(all_contributions, \"eu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# EU model\n",
    "eu_model = Word2Vec(all_toks.loc[eu_mentions.index], size=300)\n",
    "\n",
    "# Non-EU model\n",
    "neu_model = Word2Vec(all_toks.loc[non_eu_mentions.index], size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eu_ranked_words_models = get_most_changey_words_with_models(eu_model, neu_model, n=10, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'sterling'),\n",
       " (7, 'erect'),\n",
       " (8, 'ord'),\n",
       " (10, 'suing'),\n",
       " (11, 'ceta'),\n",
       " (11, 'rigidity'),\n",
       " (12, 'sifting'),\n",
       " (13, 'otiose'),\n",
       " (13, 'patriot'),\n",
       " (13, 'tra'),\n",
       " (14, 'entrenchment'),\n",
       " (14, 'exits'),\n",
       " (15, 'quangos'),\n",
       " (15, 'renegotiating'),\n",
       " (16, 'decree'),\n",
       " (16, 'exiting'),\n",
       " (16, 'lent'),\n",
       " (16, 'modifying'),\n",
       " (17, 'genetically'),\n",
       " (17, 'gras')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_ranked_words_models[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_eu, vectors_eu = get_top_vocab_and_vectors(eu_model)\n",
    "vocab_neu, vectors_neu = get_top_vocab_and_vectors(neu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eu_ranked_words_vectors = get_most_changey_words_with_vectors(vocab_eu, vocab_neu, vectors_eu, vectors_neu, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(97, 'ii'),\n",
       " (140, 'master'),\n",
       " (149, 'seemingly'),\n",
       " (165, 'sterling'),\n",
       " (185, 'honours'),\n",
       " (194, 'prisoner'),\n",
       " (203, 'correcting'),\n",
       " (204, 'terminal'),\n",
       " (214, 'contracting'),\n",
       " (219, 'remotely'),\n",
       " (229, 'conversion'),\n",
       " (229, 'gb'),\n",
       " (234, 'staying'),\n",
       " (235, 'alternatively'),\n",
       " (235, 'bypass'),\n",
       " (240, 'hunting'),\n",
       " (240, 'leaving'),\n",
       " (242, 'leavers'),\n",
       " (244, 'feeding'),\n",
       " (244, 'revolutionary')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_ranked_words_vectors[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ii',\n",
       " 'seemingly',\n",
       " 'sterling',\n",
       " 'honours',\n",
       " 'prisoner',\n",
       " 'correcting',\n",
       " 'contracting',\n",
       " 'remotely',\n",
       " 'conversion',\n",
       " 'staying']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in eu_ranked_words_vectors if check_freq(w[1],eu_model) and check_freq(w[1],neu_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii\n",
      "EU : ['arrest', 'access', '(', 'criminal', 'regulations', 'regulatory', 'court', 'regulation']\n",
      "NEU: ['st', 'c', 'george', 'elizabeth', 'james', 'b', 'insert', 'king']\n",
      "\n",
      "seemingly\n",
      "EU : ['(', 'an', 'green', 'no-', 'digital', 'page', 'climate', 'sea']\n",
      "NEU: ['completely', 'totally', 'caused', 'wholly', 'austerity', 'somewhat', 'causing', 'delay']\n",
      "\n",
      "sterling\n",
      "EU : ['NUMBER%', 'increase', 'pound', 'unemployment', 'reduction', 'exports', 'growth', 'poverty']\n",
      "NEU: ['sir', 'tribute', 'fantastic', 'tireless', 'pensions', 'predecessor', 'excellent', 'hard']\n",
      "\n",
      "honours\n",
      "EU : ['manifesto', 'delivers', 'protects', 'gave', 'deliver', 'result', 'honour', 'allows']\n",
      "NEU: ['NUMBERth', 'smith', 'justice', 'royal', 'statute', 'member', 'pension', 'lord']\n",
      "\n",
      "prisoner\n",
      "EU : ['treaty', 'directive', 'data', 'withdrawal', 'regulations', 'treaties', 'reciprocal', 'existing']\n",
      "NEU: ['officer', 'prison', 'someone', 'woman', 'child', 'prisoners', 'prisoner', 'sentence']\n",
      "\n",
      "correcting\n",
      "EU : ['delegated', 'clause', 'giving', '(', 'legislative', 'henry', 'under', 'grab']\n",
      "NEU: ['put', 'correct', 'brought', 'talking', 'telling', 'bringing', 'giving', 'expressed']\n",
      "\n",
      "contracting\n",
      "EU : ['political', 'conservative', 'labour', 'all-', 'tory', 'unionist', 'third-', 'national']\n",
      "NEU: ['carried', 'carrying', 'carry', 'set', 'setting', 'sets', 'rolled', 'pointed']\n",
      "\n",
      "remotely\n",
      "EU : ['if', 'worse', 'enough', 'extremely', 'being', 'or', 'incredibly', 'less']\n",
      "NEU: ['could', 'might', 'or', 'should', 'anywhere', 'cost-', 'being', 'if']\n",
      "\n",
      "conversion\n",
      "EU : ['chancellor', 'comments', 'remarks', 'predecessor', 'sir', 'majesty', 'john', 'words']\n",
      "NEU: ['introduction', 'marriage', 'removal', 'consent', 'status', 'closure', 'academy', 'conversion']\n",
      "\n",
      "staying\n",
      "EU : ['leaving', 'stay', 'remaining', 'remain', 'leave', 'referendum', 'membership', 'interests']\n",
      "NEU: ['living', 'staying', 'live', 'hours', 'who', 'keeping', 'waiting', 'accommodation']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"EU :\", neighbors(query, vectors_eu, vocab_eu, 8))\n",
    "    print(\"NEU:\", neighbors(query, vectors_neu, vocab_neu, 8))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sterling',\n",
       " 'honours',\n",
       " 'bypass',\n",
       " 'seemingly',\n",
       " 'contracting',\n",
       " 'prisoner',\n",
       " 'persuading',\n",
       " 'chip',\n",
       " 'super-',\n",
       " 'temporarily']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in eu_ranked_words_models if check_freq(w[1],eu_model) and check_freq(w[1],neu_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sterling\n",
      "Con: ['depreciation', 'pound', 'inflation', 'devaluation', 'decline', 'decrease', 'projected', 'earnings']\n",
      "Lab: ['tireless', 'heroic', 'jamieson', 'ethic', 'steen', 'tremendous', 'natzler', 'preparatory']\n",
      "\n",
      "honours\n",
      "Con: ['honouring', 'protects', 'delivers', 'maintains', 'secures', 'fulfils', 'retains', 'undermines']\n",
      "Lab: ['medal', 'wilfred', 'magna', 'nobel', 'stipulation', 'carta', 'yellow', 'featuring']\n",
      "\n",
      "bypass\n",
      "Con: ['initiate', 'block', 'organise', 'facilitate', 'undergo', 'assist', 'accommodate', 'allocate']\n",
      "Lab: ['aNUMBER', 'redevelopment', 'tunnel', 'mNUMBER', 'middlewich', 'dualling', 'parkway', 'ely']\n",
      "\n",
      "seemingly\n",
      "Con: ['commercialisation', 'lasers', 'steels', 'strewn', 'collars', 'caving', 'mossack', 'deteriorating']\n",
      "Lab: ['utterly', 'patently', 'inherently', 'misplaced', 'somewhat', 'bleeding', 'wholly', 'discredited']\n",
      "\n",
      "contracting\n",
      "Con: ['third-', 'transcends', 'communist', 'republican', 'socialist', 'sdlp', 'unionist', 'governing']\n",
      "Lab: ['bail-', 'phasing', 'clapped-', 'kilter', 'bailing', 'sorting', 'hollowing', 'stamping']\n",
      "\n",
      "prisoner\n",
      "Con: ['directive', 'reciprocal', 'superseding', 'directives', 'acquis', 'via', 'insolvency', 'iii']\n",
      "Lab: ['offender', 'person', 'officer', 'prisoners', 'defendant', 'clinician', 'perpetrator', 'woman']\n",
      "\n",
      "persuading\n",
      "Con: ['sandhurst', 'recalcitrant', 'supper', 'slowness', 'texting', 'helsinki', 'unveiling', 'tones']\n",
      "Lab: ['urging', 'persuade', 'convince', 'inviting', 'contacting', 'assuring', 'advising', 'telling']\n",
      "\n",
      "chip\n",
      "Con: ['bargaining', 'chips', 'pawns', 'classed', 'supplicant', 'scot', 'regarded', 'pretext']\n",
      "Lab: ['chipped', 'tucked', 'melt', 'throwing', 'pop', 'squirrel', 'snapping', 'witter']\n",
      "\n",
      "super-\n",
      "Con: ['vassal', 'islamic', 'unitary', 'deregulated', 'repressive', 'investor-', 'timber', 'counsellor']\n",
      "Lab: ['weston-', 'mare', 'wildflower-', 'sedgefield', 'berwickshire', 'whitworth', 'bexley', 'newbury']\n",
      "\n",
      "temporarily\n",
      "Con: ['unlawfully', 'plumbers', 'lawfully', 'atol-', 'disgracefully', 'costa', 'illegally', 'jeff']\n",
      "Lab: ['permanently', 'forcibly', 'parked', 'arrested', 'wrongly', 'remploy', 'detained', 'illegally']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Con:\", [x[0] for x in eu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"Lab:\", [x[0] for x in neu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remainers vs Leavers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "remain = all_contributions.query(\"ref_stance == 'remain'\")\n",
    "leave = all_contributions.query(\"ref_stance == 'leave'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# remain model\n",
    "rem_model = Word2Vec(all_toks.loc[remain.index], size=300)\n",
    "\n",
    "# leave model\n",
    "lea_model = Word2Vec(all_toks.loc[leave.index], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_rem, vectors_rem = get_top_vocab_and_vectors(rem_model)\n",
    "vocab_lea, vectors_lea = get_top_vocab_and_vectors(lea_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem_lea_ranked_words_vectors = get_most_changey_words_with_vectors(vocab_rem, vocab_lea, vectors_rem, vectors_lea, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(163, 'duck'),\n",
       " (216, 'gamble'),\n",
       " (219, 'rotten'),\n",
       " (226, 'shareholder'),\n",
       " (239, 'chaotic'),\n",
       " (252, 'mirrors'),\n",
       " (260, 'listing'),\n",
       " (261, 'dodgy'),\n",
       " (268, 'wash'),\n",
       " (274, 'dysfunctional'),\n",
       " (275, 'ii'),\n",
       " (279, 'tip'),\n",
       " (285, 'anymore'),\n",
       " (290, 'reversing'),\n",
       " (296, 'hypocrisy'),\n",
       " (298, 'nowadays'),\n",
       " (299, 'supposedly'),\n",
       " (302, 'bogus'),\n",
       " (302, 'comprehensively'),\n",
       " (302, 'scores')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_lea_ranked_words_vectors[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ii',\n",
       " 'supposedly',\n",
       " 'seemingly',\n",
       " 'similarly',\n",
       " 'hemel',\n",
       " 'eastleigh',\n",
       " 'fareham',\n",
       " 'hyde',\n",
       " 'plots',\n",
       " 'unequivocally']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in rem_lea_ranked_words_vectors if check_freq(w[1],rem_model) and check_freq(w[1],lea_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii\n",
      "Remain: ['ecris', 'database', 'prüm', 'ec', 'europol', 'eurojust', 'records', 'warrant']\n",
      "Leaver: ['vi', 'g', 'afriyie', 'k', 'f', 'v', 'borwick', 'h']\n",
      "\n",
      "supposedly\n",
      "Remain: ['roundly', 'allegedly', 'murderous', 'implying', 'imprisoned', 'overboard', 'impermissible', 'dismantled']\n",
      "Leaver: ['blatantly', 'abusing', 'sued', 'traded', 'inherently', 'corrupt', 'blockaded', 'essentially']\n",
      "\n",
      "seemingly\n",
      "Remain: ['commercialisation', 'lasers', 'steels', 'strewn', 'collars', 'caving', 'mossack', 'deteriorating']\n",
      "Leaver: ['utterly', 'patently', 'inherently', 'misplaced', 'somewhat', 'bleeding', 'wholly', 'discredited']\n",
      "\n",
      "similarly\n",
      "Remain: ['fourthly', 'furthermore', 'moreover', 'thirdly', 'secondly', 'lastly', 'meanwhile', 'crucially']\n",
      "Leaver: ['furthermore', 'moreover', 'secondly', 'likewise', 'thirdly', 'fourthly', 'lastly', 'consequently']\n",
      "\n",
      "hemel\n",
      "Remain: ['hempstead', 'warley', 'frome', 'wyre', 'chorley', 'harrogate', 'maldon', 'wentworth']\n",
      "Leaver: ['hempstead', 'rutland', 'barking', 'brentwood', 'delyn', 'epsom', 'twickenham', 'leigh']\n",
      "\n",
      "eastleigh\n",
      "Remain: ['ongar', 'congleton', 'makerfield', 'darwen', 'brentwood', 'isleworth', 'falmouth', 'selly']\n",
      "Leaver: ['cheadle', 'crawley', 'braintree', 'eastbourne', 'chippenham', 'romford', 'aldershot', 'hertsmere']\n",
      "\n",
      "fareham\n",
      "Remain: ['spelthorne', 'gedling', 'streatham', 'banbury', 'dewsbury', 'beckenham', 'lewes', 'shipley']\n",
      "Leaver: ['crawley', 'dewsbury', 'cheadle', 'romford', 'watford', 'stafford', 'burton', 'halifax']\n",
      "\n",
      "hyde\n",
      "Remain: ['stalybridge', 'kirkcaldy', 'thirsk', 'malton', 'poplar', 'stamford', 'roxburgh', 'walton']\n",
      "Leaver: ['stalybridge', 'abbot', 'newton', 'eastbourne', 'finsbury', 'middleton', 'ainsty', 'selby']\n",
      "\n",
      "plots\n",
      "Remain: ['preachers', 'islamism', 'seafarers', 'boko', 'sexually', 'victimisation', 'haram', 'perpetrate']\n",
      "Leaver: ['murders', 'attacks', 'outrages', 'foiled', 'sympathisers', 'rockets', 'atrocities', 'missiles']\n",
      "\n",
      "unequivocally\n",
      "Remain: ['categorically', 'counsellor', 'vassal', 'islamic', 'unreservedly', 'investor-', 'deadlocked', 'secular']\n",
      "Leaver: ['unreservedly', 'condemn', 'condemns', 'categorically', 'condemning', 'jubeir', 'resolute', 'emirati']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Remain:\", [x[0] for x in eu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"Leaver:\", [x[0] for x in neu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_models = dict()\n",
    "# Train a language model for various different portions of the forum.\n",
    "for w, w_posts in get_time_windows(all_contributions, 365, 365, time_column=\"date\"):\n",
    "    time_models[w] = Word2Vec(all_toks.loc[w_posts.index], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_over_time(search_term, time_models, top_n=10000):\n",
    "    for window, curr_model in time_models.items():\n",
    "        curr_vocab, curr_vectors = get_top_vocab_and_vectors(curr_model, top_n)\n",
    "        print(window)\n",
    "        if search_term in curr_vocab:\n",
    "            print(neighbors(search_term, curr_vectors, curr_vocab, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['stay', 'vote', 'go', 'lose', 'get', 'come', 'take', 'be', 'remain', 'tell', 'move', 'give']\n",
      "2016-05-17 00:00:00\n",
      "['referendum', 'remain', 'brexit', 'leaving', 'stay', 'left', 'lose', 'get', 'go', 'exit', 'voted', 'vote']\n",
      "2017-05-17 00:00:00\n",
      "['referendum', 'exit', 'leaving', 'vote', 'left', 'remain', 'stay', 'lose', 'voted', 'go', 'get', 'look']\n",
      "2018-05-17 00:00:00\n",
      "['referendum', 'remain', 'leaving', 'vote', 'stay', 'get', 'left', 'exit', 'go', 'deal', 'lose', 'come']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"leave\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['every', 'one', 'union', 'third', 'largest', 'two-', 'free', 'an', 'another', 'parent', 'each', 'any']\n",
      "2016-05-17 00:00:00\n",
      "['eu', 'union', 'european', 'free', 'common', 'labour', 'market', 'customs', 'one', 'leave', 'every', 'europe']\n",
      "2017-05-17 00:00:00\n",
      "['customs', 'union', 'labour', 'free', 'eu', 'euratom', 'common', 'eea', 'leave', 'one', 'internal', 'every']\n",
      "2018-05-17 00:00:00\n",
      "['common', 'customs', 'every', 'union', 'eu', 'labour', 'one', 'european', 'free', 'each', 'biggest', 'any']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"single\", time_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get examples for chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_over_time_comma_delimited(query, time_models, top_n=10000):\n",
    "    for window, curr_model in time_models.items():\n",
    "        curr_vocab, curr_vectors = get_top_vocab_and_vectors(curr_model, top_n)\n",
    "        if query in curr_vocab:\n",
    "            print(window.strftime(\"%y/%m/%d\"), end=\",\")\n",
    "            print(\",\".join(neighbors(query, curr_vectors, curr_vocab, 6)))\n",
    "        else:\n",
    "            print(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brexit\n",
      "15/05/18,election,leave,vote,eu,trade,european\n",
      "16/05/17,referendum,eu,negotiations,leave,vote,trade\n",
      "17/05/17,exit,eu,referendum,trade,deal,state\n",
      "18/05/17,deal,referendum,vote,backstop,union,state\n",
      "\n",
      "referendum\n",
      "15/05/18,election,vote,debate,elections,parliament,consultation\n",
      "16/05/17,election,vote,leave,brexit,debate,voted\n",
      "17/05/17,election,vote,leave,brexit,voted,negotiations\n",
      "18/05/17,vote,election,leave,brexit,voted,article\n",
      "\n",
      "immigration\n",
      "15/05/18,criminal,welfare,asylum,migration,legal,justice\n",
      "16/05/17,foreign,eu,brexit,prime,tax,migration\n",
      "17/05/17,trade,tax,eu,regulatory,legal,current\n",
      "18/05/17,trade,justice,fisheries,migration,system,eu\n",
      "\n",
      "single\n",
      "15/05/18,every,one,union,third,largest,two-\n",
      "16/05/17,eu,union,european,free,common,labour\n",
      "17/05/17,customs,union,labour,free,eu,euratom\n",
      "18/05/17,common,customs,every,union,eu,labour\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in [\"brexit\", \"referendum\", \"immigration\", \"single\"]:\n",
    "    print(query)\n",
    "    neighbours_over_time_comma_delimited(query, time_models)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changiest words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_changiest_words_per_window(time_models, top_n=10000, k=1000):\n",
    "    out_dic = dict()\n",
    "    windows = list(time_models.keys())\n",
    "    for i in range(1, len(windows)):\n",
    "        model_1 = time_models[windows[i-1]]\n",
    "        model_2 = time_models[windows[i]]\n",
    "\n",
    "        vocab_1, vectors_1 = get_top_vocab_and_vectors(model_1, top_n)\n",
    "        vocab_2, vectors_2 = get_top_vocab_and_vectors(model_2, top_n)\n",
    "\n",
    "        out_dic[windows[i]] = get_most_changey_words_with_vectors(vocab_1, vocab_2, vectors_1, vectors_2, k=k)\n",
    "\n",
    "    return out_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "changiest_words_per_window = get_changiest_words_per_window(time_models, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_changiest_over_time(changiest_words_per_window, min_freq=0):\n",
    "    for window, changey_words in changiest_words_per_window.items():\n",
    "        check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "        queries = [w[1] for w in changey_words if check_freq(w[1],model)]\n",
    "        queries = queries[:20]\n",
    "\n",
    "        print(window)\n",
    "#         t20_words = [f\"{w[1]} {w[0]}\" for w in changey_words[:20]]\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[:5]))\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[5:10]))\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[10:15]))\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[15:20]))\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "google               customs              dog                  strikes              bomb                \n",
      "smith                managing             brexit               e-                   wilson              \n",
      "haven                plain                exit                 style                initially           \n",
      "bombing              exclusively          wing                 rbs                  sunday              \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "retained             selection            osborne              salisbury            tower               \n",
      "no-                  bbc                  basically            noise                principal           \n",
      "latter               wear                 super-               shipley              donations           \n",
      "text                 leigh                namely               junior               similarly           \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "offensive            overnight            bone                 zero                 and-                \n",
      "basically            paisley              similarly            charter              grieve              \n",
      "e-                   continually          guide                constantly           defeat              \n",
      "furthermore          permanent            letwin               principal            agent               \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['tax', 'customs', 'bank', 'revenue', 'trade', 'allowance', 'government', 'border', 'gas', '(', 'european', 'pensions']\n",
      "2016-05-17 00:00:00\n",
      "['customs', 'trade', 'eu', 'credit', 'europe', 'movement', 'market', 'national', 'single', 'brexit', 'membership', 'common']\n",
      "2017-05-17 00:00:00\n",
      "['european', 'trade', 'eu', 'euratom', 'market', 'agreement', 'border', 'brexit', 'eea', 'single', 'regulatory', 'withdrawal']\n",
      "2018-05-17 00:00:00\n",
      "['european', 'backstop', 'trade', 'deal', 'eu', 'agreement', 'border', 'market', 'arrangement', 'relationship', 'regulatory', 'treaty']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"customs\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['election', 'leave', 'vote', 'eu', 'trade', 'european', 'union', 'paris', 'stay', 'he', 'bad', 'membership']\n",
      "2016-05-17 00:00:00\n",
      "['referendum', 'eu', 'negotiations', 'leave', 'vote', 'trade', 'exit', 'uncertainty', 'article', 'european', 'what', 'state']\n",
      "2017-05-17 00:00:00\n",
      "['exit', 'eu', 'referendum', 'trade', 'deal', 'state', 'economic', 'customs', 'negotiations', 'union', 'border', 'transition']\n",
      "2018-05-17 00:00:00\n",
      "['deal', 'referendum', 'vote', 'backstop', 'union', 'state', 'trade', 'austerity', 'what', 'leave', 'exit', 'prime']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"brexit\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['NUMBER%', 'rate', 'emissions', 'lower', 'gdp', 'zero', 'low', 'deficit', 'per', 'higher', 'reduction', 'price']\n",
      "2016-05-17 00:00:00\n",
      "['rate', 'lower', 'income', 'low', '£', 'higher', 'average', 'rates', 'prices', 'increased', 'gdp', 'increase']\n",
      "2017-05-17 00:00:00\n",
      "['homes', 'average', 'rate', '£', 'zero', 'lower', 'tariffs', 'per', 'income', 'rates', 'gdp', 'growth']\n",
      "2018-05-17 00:00:00\n",
      "['carbon', 'emissions', 'NUMBER%', 'net', '£', 'tariffs', 'reduce', 'rate', 'gdp', 'tariff', 'reduction', 'growth']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"zero\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['st', 'constituency', 'city', 'station', 'street', 'college', 'manchester', 'cities', 'borough', 'county', 'university', 'towns']\n",
      "2016-05-17 00:00:00\n",
      "['st', 'hospital', 'town', 'borough', 'constituency', 'royal', 'county', 'park', 'college', 'city', 'east', 'street']\n",
      "2017-05-17 00:00:00\n",
      "['grenfell', 'fire', 'blocks', 'homes', 'cladding', 'accommodation', 'residents', 'tragedy', 'hospital', 'buildings', 'happened', 'living']\n",
      "2018-05-17 00:00:00\n",
      "['tower', 'killed', 'fire', 'london', 'visited', 'constituency', 'station', 'died', 'grenfell', 'st', 'street', 'streets']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"tower\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['benefit', 'pension', 'income', 'impact', 'payment', 'overseas', 'insurance', 'licence', 'compensation', 'eu', 'annual', 'exemption']\n",
      "2016-05-17 00:00:00\n",
      "['brexit', 'negotiations', 'article', 'membership', 'referendum', 'leave', 'eu', 'agreement', 'withdrawal', 'trade', 'leaving', 'departure']\n",
      "2017-05-17 00:00:00\n",
      "['withdrawal', 'brexit', 'eu', 'law', 'leave', 'negotiations', 'agreement', 'implementation', 'referendum', 'statute', 'legislation', 'transition']\n",
      "2018-05-17 00:00:00\n",
      "['article', 'leave', 'withdrawal', 'extension', 'eu', 'leaving', 'implementation', 'brexit', 'backstop', 'departure', 'negotiations', 'deal']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"exit\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['to-', 'nuclear', 'isil', 'co-', 'high-', 'non-', 'no-', 'anti-', 'assad', 'two-', 'air', 'without']\n",
      "2016-05-17 00:00:00\n",
      "['nuclear', 'property', 'non-', 'border', 'car', 'power', 'offence', 'zone', 'or', 'global', 'on-', 'solution']\n",
      "2017-05-17 00:00:00\n",
      "['with', 'bad', 'great', 'brexit', 'transitional', 'transition', 'no', 'trade', 'customs', 'cliff', 'without', 'post-']\n",
      "2018-05-17 00:00:00\n",
      "['no', 'without', 'scenario', 'negotiated', 'vote', 'bad', 'exit', 'trade', 'post-', 'great', 'brexit', 'any']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"no-\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['state', 'home', 'permanent', 'cabinet', 'chief', 'defence', 'financial', 'health', 'private', 'justice', 'pensions', 'former']\n",
      "2016-05-17 00:00:00\n",
      "['home', 'state', 'permanent', 'cabinet', 'defence', 'chief', 'justice', 'financial', 'un', 'states', 'private', 'former']\n",
      "2017-05-17 00:00:00\n",
      "['home', 'state', 'foreign', 'cabinet', 'environment', 'former', 'homes', 'accommodation', 'financial', 'private', 'housing', 'temporary']\n",
      "2018-05-17 00:00:00\n",
      "['permanent', 'foreign', 'home', 'customs', 'cabinet', 'general', 'transport', 'chief', 'defence', 'trade', 'environment', 'brexit']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"permanent\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brexit\n",
      "15/05/18,election,leave,vote,eu,trade,european\n",
      "16/05/17,referendum,eu,negotiations,leave,vote,trade\n",
      "17/05/17,exit,eu,referendum,trade,deal,state\n",
      "18/05/17,deal,referendum,vote,backstop,union,state\n",
      "\n",
      "customs\n",
      "15/05/18,tax,customs,bank,revenue,trade,allowance\n",
      "16/05/17,customs,trade,eu,credit,europe,movement\n",
      "17/05/17,european,trade,eu,euratom,market,agreement\n",
      "18/05/17,european,backstop,trade,deal,eu,agreement\n",
      "\n",
      "strike\n",
      "15/05/18,take,taken,industrial,buy,action,military\n",
      "16/05/17,strike,get,carry,thing,war,taken\n",
      "17/05/17,get,bring,strike,carry,put,give\n",
      "18/05/17,reach,get,negotiate,be,move,strike\n",
      "\n",
      "tower\n",
      "15/05/18,st,constituency,city,station,street,college\n",
      "16/05/17,st,hospital,town,borough,constituency,royal\n",
      "17/05/17,grenfell,fire,blocks,homes,cladding,accommodation\n",
      "18/05/17,tower,killed,fire,london,visited,constituency\n",
      "\n",
      "salisbury\n",
      "15/05/18,st,royal,john,tribute,sir,james\n",
      "16/05/17,hon,south,states,east,north,west\n",
      "17/05/17,attack,syria,yemen,terrorist,war,grenfell\n",
      "18/05/17,killed,war,attacks,events,syria,died\n",
      "\n",
      "no-\n",
      "15/05/18,to-,nuclear,isil,co-,high-,non-\n",
      "16/05/17,nuclear,property,non-,border,car,power\n",
      "17/05/17,with,bad,great,brexit,transitional,transition\n",
      "18/05/17,no,without,scenario,negotiated,vote,bad\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in [\"brexit\", \"customs\", \"strike\", \"tower\", \"salisbury\", \"no-\"]:\n",
    "    print(query)\n",
    "    neighbours_over_time_comma_delimited(query, time_models)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changiest Words Conservative vs Labour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "con_time_models = dict()\n",
    "lab_time_models = dict()\n",
    "# Train a language model for various different portions of the forum.\n",
    "for w, w_posts in get_time_windows(all_contributions, 365, 365, time_column=\"date\"):\n",
    "    curr_con = w_posts[w_posts.index.isin(conservatives.index)].index\n",
    "    curr_lab = w_posts[w_posts.index.isin(labour.index)].index\n",
    "    \n",
    "    con_time_models[w] = Word2Vec(all_toks.loc[curr_con], size=300)\n",
    "    lab_time_models[w] = Word2Vec(all_toks.loc[curr_lab], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "con_changiest_words_per_window = get_changiest_words_per_window(con_time_models, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "dual                 customs              google               trusted              reflecting          \n",
      "selection            english              blue                 red                  naturally           \n",
      "strikes              exit                 settled              cheap                precious            \n",
      "campaigners          similarly            pause                closures             indian              \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "selection            thereafter           retained             henry                style               \n",
      "text                 depth                similarly            shock                hopes               \n",
      "naturally            semitism             scenario             salisbury            banning             \n",
      "advertising          apparent             radio                largely              permanent           \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "magistrates          nerve                defeat               essentially          warning             \n",
      "e-                   calm                 henry                politically          virtually           \n",
      "similarly            advertising          profoundly           latter               permanent           \n",
      "naturally            carillion            austerity            beat                 demanding           \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(con_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_neighours(query):\n",
    "    print(\"Conservative\")\n",
    "    neighbours_over_time(query, con_time_models)\n",
    "    print(\"\\nLabour\")\n",
    "    neighbours_over_time(query, lab_time_models)\n",
    "    \n",
    "def compare_neighours_comma_delimited(query):\n",
    "    print(\"Conservative\")\n",
    "    neighbours_over_time_comma_delimited(query, con_time_models)\n",
    "    print(\"\\nLabour\")\n",
    "    neighbours_over_time_comma_delimited(query, lab_time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,daesh,syria,isil,conflict,labour,threat\n",
      "16/05/17,war,person,problem,(,party,insert\n",
      "17/05/17,court,legislation,agreement,arrangements,circumstances,weapons\n",
      "18/05/17,border,brexit,risk,backstop,referendum,union\n",
      "\n",
      "Labour\n",
      "15/05/18,review,spending,budget,poverty,past,recent\n",
      "16/05/17,crisis,year,world,investment,economy,nhs\n",
      "17/05/17,NUMBER%,problem,country,law,government,legislation\n",
      "18/05/17,austerity,deal,crisis,brexit,years,credit\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"chaos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,isil,long-,of-,to-,illegal,into\n",
      "16/05/17,&,between,car,mobile,nuclear,parking\n",
      "17/05/17,without,no,with,customs,free,trade\n",
      "18/05/17,no,without,brexit,negotiated,eu,scenario\n",
      "\n",
      "Labour\n",
      "15/05/18,into,high-,to-,between,or,against\n",
      "16/05/17,long-,year-,free,&,between,low-\n",
      "17/05/17,long-,with,no,transitional,deal,between\n",
      "18/05/17,no,brexit,trade,customs,without,any\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"no-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,s,trade,taxpayers,european,billion,gas\n",
      "16/05/17,eu,customs,trade,europe,international,market\n",
      "17/05/17,european,eu,trade,agreement,euratom,market\n",
      "18/05/17,european,eu,backstop,trade,agreement,deal\n",
      "\n",
      "Labour\n",
      "15/05/18,’,energy,majesty,chief,allowance,department\n",
      "16/05/17,eu,trade,customs,union,market,single\n",
      "17/05/17,european,trade,eu,agreement,market,single\n",
      "18/05/17,european,trade,eu,deal,agreement,market\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"customs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,£,income,rate,NUMBER%,exit,insurance\n",
      "16/05/17,eu,negotiations,european,trade,brexit,leave\n",
      "17/05/17,eu,withdrawal,leave,law,negotiations,legislation\n",
      "18/05/17,eu,leave,period,leaving,agreement,deal\n",
      "\n",
      "Labour\n",
      "15/05/18,income,impact,increase,eu,tax,NUMBER%\n",
      "16/05/17,european,trade,union,brexit,market,agreement\n",
      "17/05/17,eu,agreement,period,brexit,european,leave\n",
      "18/05/17,eu,withdrawal,article,trade,customs,exit\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lab_changiest_words_per_window = get_changiest_words_per_window(lab_time_models, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "mixed                right-               bold                 bearing              bombing             \n",
      "empty                promising            scenario             irresponsible        firmly              \n",
      "presumably           tremendous           airstrikes           actively             managing            \n",
      "ill-                 fashion              map                  facility             court               \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "selection            basically            bbc                  electorate           channels            \n",
      "lacking              fashion              empty                title                respects            \n",
      "thoroughly           dreadful             backwards            presumably           content             \n",
      "tremendous           bearing              precious             presenting           chemical            \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "politically          fashion              basically            bearing              far-                \n",
      "safely               restoration          precious             preferred            apparent            \n",
      "exact                pfi                  renewal              zero                 correctly           \n",
      "secret               detention            lie                  offensive            taskforce           \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(lab_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,sovereign,european,rights,united,protect,own\n",
      "16/05/17,united,leader,sovereign,democratic,law,pension\n",
      "17/05/17,nuclear,global,united,european,nation,british\n",
      "18/05/17,sovereign,customs,law,nation,democratic,british\n",
      "\n",
      "Labour\n",
      "15/05/18,member,united,affairs,(,office,leader\n",
      "16/05/17,united,vote,members,leader,gentleman,welsh\n",
      "17/05/17,must,security,our,across,international,vital\n",
      "18/05/17,vote,(,parliament,united,rights,country\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"sovereign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,sovereignty,membership,security,law,human,nation\n",
      "16/05/17,parliament,party,vote,leader,sovereignty,members\n",
      "17/05/17,parliament,democracy,law,role,control,scrutiny\n",
      "18/05/17,interests,democracy,referendum,vote,decision,voted\n",
      "\n",
      "Labour\n",
      "15/05/18,union,role,membership,eu,european,security\n",
      "16/05/17,debate,party,leader,parliament,house,statement\n",
      "17/05/17,party,parliament,members,democracy,committee,debate\n",
      "18/05/17,party,deal,economy,country,democracy,vote\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"sovereignty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,couple,little,page,”,insert,short\n",
      "16/05/17,eu,referendum,negotiations,trade,union,european\n",
      "17/05/17,eu,agreement,trade,period,negotiations,union\n",
      "18/05/17,deal,referendum,vote,union,party,agreement\n",
      "\n",
      "Labour\n",
      "15/05/18,member,party,election,leader,european,united\n",
      "16/05/17,eu,referendum,vote,what,us,european\n",
      "17/05/17,trade,foreign,state,eu,customs,deal\n",
      "18/05/17,deal,state,trade,vote,prime,eu\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"brexit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changiest Words Remain vs Leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem_time_models = dict()\n",
    "lea_time_models = dict()\n",
    "# Train a language model for various different portions of the forum.\n",
    "for w, w_posts in get_time_windows(all_contributions, 365, 365, time_column=\"date\"):\n",
    "    curr_rem = w_posts[w_posts.index.isin(remain.index)].index\n",
    "    curr_lea = w_posts[w_posts.index.isin(leave.index)].index\n",
    "    \n",
    "    rem_time_models[w] = Word2Vec(all_toks.loc[curr_rem], size=300)\n",
    "    lea_time_models[w] = Word2Vec(all_toks.loc[curr_lea], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_neighours(query):\n",
    "    print(\"Remain\")\n",
    "    neighbours_over_time(query, rem_time_models)\n",
    "    print(\"\\nLeave\")\n",
    "    neighbours_over_time(query, lea_time_models)\n",
    "    \n",
    "def compare_neighours_comma_delimited(query):\n",
    "    print(\"Remain\")\n",
    "    neighbours_over_time_comma_delimited(query, rem_time_models)\n",
    "    print(\"\\nLeave\")\n",
    "    neighbours_over_time_comma_delimited(query, lea_time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem_changiest_words_per_window = get_changiest_words_per_window(rem_time_models, 5000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "cell                 facility             customs              dog                  exit                \n",
      "tv                   managing             bomb                 e-                   for-                \n",
      "precious             pubs                 currency             mature               autonomy            \n",
      "routinely            search               brexit               gift                 google              \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "retained             sterling             salisbury            settled              radio               \n",
      "wear                 principal            collectively         solely               NUMBERg             \n",
      "precious             games                privatisation        block                c                   \n",
      "fresh                text                 title                nationally           natural             \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "continually          basically            cold                 overnight            presumably          \n",
      "search               freight              precious             principal            temporary           \n",
      "starts               warning              neutral              queen                cheap               \n",
      "defeat               hopes                permanently          card                 continuous          \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(rem_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lea_changiest_words_per_window = get_changiest_words_per_window(lea_time_models, 5000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "barnett              dates                explaining           lock                 re-                 \n",
      "command              elect                orders               selection            passing             \n",
      "definitely           discover             english              readily              signs               \n",
      "standing             undoubtedly          books                conviction           divorce             \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "selection            restored             stance               tribunal             precise             \n",
      "tower                partisan             dates                calls                complaints          \n",
      "count                radio                secondary            content              explaining          \n",
      "intent               requests             substance            worthy               appropriately       \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "sound                temporary            claiming             counter              open-               \n",
      "charter              deposit              grasp                stuck                breaks              \n",
      "extreme              tested               acting               breaking             content             \n",
      "disastrous           threatening          weapon               definitely           warning             \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(lea_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain\n",
      "15/05/18,member,secretary,devolved,democratic,european,sovereign\n",
      "16/05/17,united,sovereign,democracy,vote,voted,british\n",
      "17/05/17,united,democratic,nuclear,nation,member,british\n",
      "18/05/17,british,united,democracy,nation,independent,democratic\n",
      "\n",
      "Leave\n",
      "15/05/18,european,eu,nation,security,protect,rights\n",
      "16/05/17,european,british,referendum,leader,eu,kingdom\n",
      "17/05/17,united,member,european,trade,customs,uk\n",
      "18/05/17,customs,eu,united,law,uk,our\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"sovereign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain\n",
      "15/05/18,deficit,problem,election,situation,point,budget\n",
      "16/05/17,problem,country,point,thing,put,position\n",
      "17/05/17,position,country,problem,point,speech,situation\n",
      "18/05/17,country,deal,situation,point,house,position\n",
      "\n",
      "Leave\n",
      "15/05/18,set,year,NUMBER%,made,carried,million\n",
      "16/05/17,set,point,pointed,were,had,carried\n",
      "17/05/17,have,get,eu,go,take,let\n",
      "18/05/17,“,being,were,£,),own\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"mess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain\n",
      "15/05/18,political,welfare,democratic,strong,cross-,effective\n",
      "16/05/17,effective,global,our,sustainable,important,positive\n",
      "17/05/17,low,strong,different,long-,positive,competitive\n",
      "18/05/17,sustainable,strong,cross-,global,framework,based\n",
      "\n",
      "Leave\n",
      "15/05/18,million,compared,households,homes,£,billion\n",
      "16/05/17,its,all-,our,sector,long-,year\n",
      "17/05/17,s,am,withdrawal,customs,trade,national\n",
      "18/05/17,(,new,withdrawal,trading,partnership,long-\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"progressive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_language_change",
   "language": "python",
   "name": "thesis_language_change"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
