{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/Eddie/Documents/language-change-methods/word_lists/function_words.txt\") as func_file:\n",
    "    function_words = [line.strip().lower() for line in func_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_FP = \"C:/Users/Eddie/Documents/Datasets/commons.db\"\n",
    "hansard_dir = \"C:/Users/Eddie/Documents/hansard-stuff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, hansard_dir + \"/Analysis/pipeline\")\n",
    "sys.path.insert(1, \"C:/Users/Eddie/Documents/language-change-methods\")\n",
    "\n",
    "from utility_functions import get_data_windows, get_time_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_fp = hansard_dir + \"/key-dates.csv\"\n",
    "\n",
    "key_dates = pd.read_csv(dates_fp, delimiter=\"\\t\")\n",
    "\n",
    "convert_to_date = lambda x: datetime.strptime(x, \"%d-%m-%Y\")\n",
    "key_dates[\"date\"] = key_dates[\"date\"].apply(convert_to_date)\n",
    "key_dates.set_index(\"date\", inplace=True)\n",
    "key_dates = key_dates.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_all_posts =\"\"\"\n",
    "SELECT c.uid, m.name, m.PimsId, p.party, d.date, c.body, c.topic, c.section, s.tmay_deal, s.benn_act, s.ref_stance, s.constituency_leave, c.usas_file\n",
    "FROM contributions as c\n",
    "INNER JOIN members as m\n",
    "ON m.PimsId = c.member\n",
    "INNER JOIN debates as d\n",
    "ON d.uid = c.debate\n",
    "INNER JOIN member_party as p\n",
    "ON p.PimsId = m.PimsId\n",
    "INNER JOIN member_stances as s\n",
    "ON s.PimsId = m.PimsId\n",
    "WHERE (d.date BETWEEN date(\"2015-05-01\") AND date(\"2019-09-10\"))\n",
    "AND (((d.date BETWEEN p.start AND p.end) AND NOT (p.end IS NULL))\n",
    "OR ((d.date >= p.start) AND (p.end IS NULL)));\"\"\".strip()\n",
    "\n",
    "# regex for identifying EU/brexit mentions\n",
    "eu_regex = r'\\b(EU|[Ee]uropean [Uu]nion|[Bb]rexit)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(DB_FP)\n",
    "curs = conn.cursor()\n",
    "\n",
    "# Gets all the contributions and creates a nice dataframe\n",
    "all_contributions = pd.read_sql_query(sql_get_all_posts, conn)\n",
    "all_contributions.columns = ['uid', 'name', 'PimsId', 'party', 'date', 'text', 'topic', 'section', 'tmay_deal', 'benn_act', 'ref_stance', 'constituency_leave', 'usas_file']\n",
    "all_contributions.set_index(\"uid\", inplace=True)\n",
    "convert_to_date = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "all_contributions['date'] = all_contributions['date'].apply(convert_to_date)\n",
    "all_contributions.sort_values(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from text_processing import clean_text, spacy_tokenise# spacy_pos\n",
    "from text_processing import ucrel_tokenise\n",
    "import nltk\n",
    "import regex as re    \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', parser=False, entity=False, matcher=False, add_vectors=False)\n",
    "\n",
    "def tokenise(text):\n",
    "    cleaned = clean_text(text)\n",
    "    cleaned = re.sub(r\"(\\p{P})\\p{P}*\", r\"\\1 \", cleaned)\n",
    "    tokens = spacy_tokenise(cleaned)\n",
    "    return tokens\n",
    "\n",
    "all_toks =  all_contributions[\"text\"].apply(tokenise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_vocab_and_vectors(model, n=10000):\n",
    "    \"\"\"\n",
    "    Gets the top n words from the model's vocabulary and the vectors of these words.\n",
    "    \"\"\"\n",
    "    top_vocab = sorted(model.wv.vocab.keys(), key=lambda x: model.wv.vocab[x].count, reverse=True)[:n]\n",
    "    top_vectors = np.array([model.wv[t] for t in top_vocab])\n",
    "    return top_vocab, top_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_vectors(model, voc_fp, vec_fp):\n",
    "    vocs = sorted(model.wv.vocab.keys(), key=lambda x: model.wv.vocab[x].count, reverse=True)[:10000]\n",
    "    vecs = np.array([model.wv[t] for t in vocs])\n",
    "    \n",
    "    with open(voc_fp, 'w') as voc_file:\n",
    "        json.dump(vocs, voc_file)\n",
    "        \n",
    "    np.save(vec_fp, vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# suppress some deprecation warning..\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR = \"C:/Users/Eddie/Documents/Datasets/Hansard Output/Embedding_Models\"\n",
    "LOAD = False\n",
    "# LOAD = os.path.exists('word_vectors/static/word_vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model on all contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "curr_dir = os.path.join(EMB_DIR, \"static\")\n",
    "check_dir(curr_dir)\n",
    "\n",
    "if LOAD:\n",
    "    print(\"Loading Model\")\n",
    "#     model = Word2Vec.load('word_vectors/w2v_all_contributions_static.npy')\n",
    "    with open(os.path.join(curr_dir, 'vocab_all.json')) as voc_file:\n",
    "        vocs = json.load(voc_file)\n",
    "    vecs = np.load(os.path.join(curr_dir, 'word_vectors_all.npy'))\n",
    "else:\n",
    "    # training the model\n",
    "    print(\"Training model\")\n",
    "    model = Word2Vec(all_toks, size=300)\n",
    "    # model.save('word_vectors/w2v_all_contributions_static.bin')\n",
    "    \n",
    "    save_word_vectors(model, \n",
    "                      os.path.join(curr_dir, 'vocab_all.json'), \n",
    "                      os.path.join(curr_dir, 'word_vectors_all.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10000 = sorted(model.wv.vocab.keys(), key=lambda x: model.wv.vocab[x].count, reverse=True)[:10000]\n",
    "top_vectors = np.array([model.wv[t] for t in t10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 38474\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size: {}\".format(len(model.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           3825357\n",
      "       the 2803252\n",
      "         , 1860753\n",
      "         . 1806067\n",
      "        to 1448369\n",
      "        of 1145774\n",
      "      that 1130004\n",
      "       and 1095262\n",
      "        in 839871\n",
      "         a 724597\n"
     ]
    }
   ],
   "source": [
    "def show_top_token_freq(model,topn):\n",
    "    for w, v in sorted(list(model.wv.vocab.items()), key=lambda x:x[1], reverse=True)[:topn]:\n",
    "        if topn<=20:\n",
    "            print(f\"{w:>10s} {v.count:5d}\")\n",
    "        else:\n",
    "            print(f\"{w}({v.count}), \", end=\"\")\n",
    "            \n",
    "show_top_token_freq(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brexit:\n",
      "['mortem(0.53850)', 'mortems(0.49493)', 'exit(0.49236)', 'referendum(0.46494)', 'renegotiation(0.43924)', 'brexiteers(0.42415)', 'negotiation(0.40236)', 'ttip(0.39831)', 'pre(0.39447)', 'departure(0.39091)']\n",
      "--------------------\n",
      "eu:\n",
      "['eea(0.71529)', 'european(0.68049)', 'euratom(0.67783)', 'euNUMBER(0.67759)', 'eurozone(0.58657)', 'cfp(0.57848)', 'echr(0.55715)', 'europe(0.55293)', 'euro(0.53939)', 'efta(0.52098)']\n",
      "--------------------\n",
      "union:\n",
      "['union-(0.55473)', 'eu(0.52017)', 'pan-(0.51891)', 'superstate(0.50384)', 'convention(0.44481)', 'euratom(0.44203)', 'euNUMBER(0.43036)', 'declarations(0.43011)', 'cfp(0.41721)', 'unions(0.41643)']\n",
      "--------------------\n",
      "european:\n",
      "['eu(0.68049)', 'soviet(0.59709)', 'crowns(0.57066)', 'customs(0.54882)', 'euratom(0.52345)', 'subscriptions(0.51557)', 'cinematograph(0.51187)', 'reps(0.49368)', 'europe(0.49334)', 'efta(0.48609)']\n",
      "--------------------\n",
      "europe:\n",
      "['continent(0.58956)', 'world(0.58794)', 'eu(0.55293)', 'balkans(0.55054)', 'mediterranean(0.54511)', 'globe(0.54511)', 'britain(0.52814)', 'france(0.50199)', 'africa(0.50148)', 'gulf(0.49860)']\n",
      "--------------------\n",
      "remainers:\n",
      "['brexiteers(0.49734)', 'eurosceptics(0.44680)', 'brexiteer(0.44060)', 'remoaners(0.43012)', 'msps(0.42890)', 'remainer(0.42157)', 'voters(0.42001)', 'democrats(0.40982)', 'commentators(0.39388)', 'liberals(0.39180)']\n",
      "--------------------\n",
      "trade:\n",
      "['tariff-(0.56379)', 'trading(0.54459)', 'marketeer(0.48407)', 'trades(0.46350)', 'subsidy-(0.45680)', 'protectionist(0.45343)', 'barrier-(0.44410)', 'bilateral(0.44290)', 'gluten-(0.44065)', 'tobacco-(0.43974)']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def get_word_similarity(model, word, topn=10):\n",
    "    if model.wv.__contains__(word):\n",
    "        vecs = [f\"{w}({v:.5f})\" for w, v in model.wv.most_similar(word)]\n",
    "        print(f\"{word}:\\n{vecs}\")\n",
    "    else:\n",
    "        print(f\"'{word}' not found in this model\")\n",
    "    print(\"--\"*10)\n",
    "\n",
    "words = ['brexit', 'eu', 'union', 'european', 'europe', 'remainers', 'trade']\n",
    "\n",
    "for word in words:\n",
    "     get_word_similarity(model,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       remainer: 0.4594\n",
      "parliamentarian: 0.4274\n",
      "     campaigner: 0.4274\n",
      "  devolutionist: 0.4258\n",
      "     politician: 0.4162\n",
      "    eurosceptic: 0.4117\n",
      "       defender: 0.4107\n",
      "       believer: 0.4087\n",
      "        marxist: 0.4060\n",
      "      socialist: 0.4038\n"
     ]
    }
   ],
   "source": [
    "result = model.wv.most_similar(positive=['remain', 'brexiteer'], negative=['leave'])\n",
    "for word, score in result:\n",
    "    print(f\"{word:>15s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get neighbours of keywords for chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "election,vote,elections,brexit,leave,voted,votes,article,parliament,negotiations\n",
      "referendum,exit,deal,vote,eu,austerity,negotiations,devolution,backstop,outcome\n",
      "migration,asylum,welfare,fisheries,detention,border,trade,visa,migrants,sanctions\n",
      "stay,remain,referendum,leaving,left,exit,lose,leaves,go,vote\n"
     ]
    }
   ],
   "source": [
    "queries = [\"referendum\", \"brexit\", \"immigration\", \"leave\"]\n",
    "for query in queries:\n",
    "#     print(query)\n",
    "    print(\",\".join(neighbors(query, top_vectors, t10000, 10)))\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(query : str,\n",
    "              embs: np.ndarray,\n",
    "              vocab: list,\n",
    "              K : int = 3) -> list:\n",
    "    sims = np.dot(embs[vocab.index(query),],embs.T)\n",
    "    output = []\n",
    "    for sim_idx in sims.argsort()[::-1][1:(1+K)]:\n",
    "        if sims[sim_idx] > 0:\n",
    "            output.append(vocab[sim_idx])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_changey_words_with_models(model1, model2, n=100, k=1000, top_n=None):\n",
    "    nn_scores = []\n",
    "    \n",
    "    top_vocab = sorted(model1.wv.vocab.keys(), key=lambda x: model1.wv.vocab[x].count, reverse=True)[:top_n]\n",
    "    \n",
    "    vocab1 = model1.wv.vocab\n",
    "    vocab2 = model2.wv.vocab\n",
    "    # Loop through all the words in the vocab\n",
    "    for w in vocab1:\n",
    "        if (w not in function_words \n",
    "                and w in vocab1 \n",
    "                and w in vocab2 \n",
    "                and vocab1[w].count > n \n",
    "                and vocab2[w].count > n \n",
    "                and w in top_vocab):\n",
    "            neighbours1 = set([x[0] for x in model1.wv.most_similar(w, topn=k)])\n",
    "            neighbours2 = set([x[0] for x in model2.wv.most_similar(w, topn=k)])\n",
    "            nn_scores.append((len(neighbours1.intersection(neighbours2)), w))\n",
    "            \n",
    "    nn_scores_sorted = sorted(nn_scores)\n",
    "    return nn_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_changey_words_with_vectors(vocab1, vocab2, vectors1, vectors2, n=20, k=1000):\n",
    "    nn_scores = []\n",
    "    # Loop through all the words in the vocab\n",
    "    for w in vocab1:\n",
    "        if w not in function_words and w in vocab1 and w in vocab2:\n",
    "            neighbours1 = set(neighbors(w, vectors1, vocab1, k))\n",
    "            neighbours2 = set(neighbors(w, vectors2, vocab2, k))\n",
    "            nn_scores.append((len(neighbours1.intersection(neighbours2)), w))\n",
    "            \n",
    "    nn_scores_sorted = sorted(nn_scores)\n",
    "    return nn_scores_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labour vs Conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservatives = all_contributions.query(\"party == 'Conservative'\")\n",
    "labour = all_contributions.query(\"party == 'Labour'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Conservative model\n",
    "con_model = Word2Vec(all_toks.loc[conservatives.index], size=300)\n",
    "\n",
    "# Labour model\n",
    "lab_model = Word2Vec(all_toks.loc[labour.index], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ranked_words_models = get_most_changey_words_with_models(con_model, lab_model, n=10, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 'lab'),\n",
       " (17, 'ea'),\n",
       " (20, 'honours'),\n",
       " (21, 'con'),\n",
       " (21, 'faraday'),\n",
       " (22, 'disappears'),\n",
       " (24, 'nudge'),\n",
       " (25, 'caseload'),\n",
       " (25, 'indcs'),\n",
       " (25, 'straightaway'),\n",
       " (26, 'renationalisation'),\n",
       " (27, 'decant'),\n",
       " (27, 'ordinarily'),\n",
       " (28, 'speculated'),\n",
       " (29, 'accomplished'),\n",
       " (29, 'nettle'),\n",
       " (29, 'settles'),\n",
       " (29, 'spun'),\n",
       " (30, 'mandating'),\n",
       " (30, 'reaping')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_words_models[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_con, vectors_con = get_top_vocab_and_vectors(con_model)\n",
    "vocab_lab, vectors_lab = get_top_vocab_and_vectors(lab_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ranked_words_vectors = get_most_changey_words_with_vectors(vocab_con, vocab_lab, vectors_con, vectors_lab, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(197, 'honours'),\n",
       " (197, 'mirrors'),\n",
       " (209, 'bypass'),\n",
       " (215, 'presiding'),\n",
       " (230, 'continuously'),\n",
       " (235, 'supposedly'),\n",
       " (274, 'manual'),\n",
       " (276, 'redditch'),\n",
       " (280, 'deane'),\n",
       " (283, 'promptly'),\n",
       " (285, 'harlow'),\n",
       " (286, 'seemingly'),\n",
       " (287, 'inadvertently'),\n",
       " (292, 'revolutionary'),\n",
       " (303, 'naturally'),\n",
       " (306, 'duck'),\n",
       " (307, 'continually'),\n",
       " (314, 'stirling'),\n",
       " (315, 'remotely'),\n",
       " (323, 'bogus')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_words_vectors[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Examples with Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mirrors',\n",
       " 'presiding',\n",
       " 'supposedly',\n",
       " 'harlow',\n",
       " 'seemingly',\n",
       " 'inadvertently',\n",
       " 'naturally',\n",
       " 'continually',\n",
       " 'stirling',\n",
       " 'bogus']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in ranked_words_vectors if check_freq(w[1],con_model) and check_freq(w[1],lab_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mirrors\n",
      "Con: ['provides', 'contains', 'applies', 'seeks', 'covers', 'repeal', 'includes', 'relating']\n",
      "Lab: ['likely', 'getting', 'becoming', 'words', 'self-', 'who', 'from', 'political']\n",
      "\n",
      "presiding\n",
      "Con: ['police', 'senior', 'officer', 'prison', 'crown', 'presiding', 'director', 'royal']\n",
      "Lab: ['weekend', 'years', 'austerity', 'decades', 'decade', 'half', 'presided', 'taking']\n",
      "\n",
      "supposedly\n",
      "Con: ['whose', 'old', 'by', 'liberal', 'convicted', 'killed', 'acts', 'man']\n",
      "Lab: ['company', 'property', 'workers', 'less', 'based', 'trade', 'organisation', 'non-']\n",
      "\n",
      "harlow\n",
      "Con: ['st', 'constituency', 'town', 'valley', 'mid', 'west', 'park', 'county']\n",
      "Lab: ['hon', ')', 'friend', 'sir', 'dr', 'john', 'lady', 'david']\n",
      "\n",
      "seemingly\n",
      "Con: ['sedentary', 'woman', 'an', ')', 'there', 'so-', 'death', 'person']\n",
      "Lab: ['brexit', 'financial', 'caused', 'zero-', 'energy', 'rhetoric', 'delay', 'drug']\n",
      "\n",
      "inadvertently\n",
      "Con: ['anything', 'harm', 'damage', 'otherwise', 'inadvertently', 'any', 'anyone', 'anybody']\n",
      "Lab: ['tell', 'remind', 'assure', 'update', 'commons', 'statement', 'explain', 'lords']\n",
      "\n",
      "naturally\n",
      "Con: ['often', 'frankly', 'because', 'afraid', 'though', 'where', 'obviously', 'otherwise']\n",
      "Lab: ['businesses', 'residents', 'these', 'constituents', 'whose', 'thousands', 'disabled', 'those']\n",
      "\n",
      "continually\n",
      "Con: ['how', 'constantly', 'properly', 'forward', 'carefully', 'continually', 'determined', 'regularly']\n",
      "Lab: ['failed', 'already', 'concerns', 'pleased', 'glad', 'warned', '(', 'why']\n",
      "\n",
      "stirling\n",
      "Con: ['south', 'stirling', 'town', 'north', 'constituency', 'manchester', 'cornwall', 'st']\n",
      "Lab: ['friend', 'sir', 'south', 'friends', 'member', 'john', 'st', 'lady']\n",
      "\n",
      "bogus\n",
      "Con: ['colleges', 'schools', 'technical', 'gone', 'unfair', 'college', 'inappropriate', 'school']\n",
      "Lab: ['zero-', 'employed', 'low', 'employment', 'low-', 'fees', 'driving', 'tribunal']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Con:\", neighbors(query, vectors_con, vocab_con, 8))\n",
    "    print(\"Lab:\", neighbors(query, vectors_lab, vocab_lab, 8))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thereafter',\n",
       " 'mirrors',\n",
       " 'nationwide',\n",
       " 'presiding',\n",
       " 'super-',\n",
       " 'supposedly',\n",
       " 'ideally',\n",
       " 'alert',\n",
       " 'like-',\n",
       " 'simultaneously']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in ranked_words_models if check_freq(w[1],con_model) and check_freq(w[1],lab_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thereafter\n",
      "Con: ['afterwards', 'subsequent', 'commence', 'until', 'dissolution', 'revaluation', 'recess', 'immediately']\n",
      "Lab: ['wounding', 'traineeship', 'apache', 'melton', 'atcham', 'clydebridge', 'frome', 'tapers']\n",
      "\n",
      "mirrors\n",
      "Con: ['criminalises', 'amends', 'repeals', 'defunct', 'streamlines', 'hybrid', 'authorises', 'skelly']\n",
      "Lab: ['soundbites', 'smoke', 'hordes', 'reactionary', 'enthused', 'shirkers', 'bureaucrats', 'insults']\n",
      "\n",
      "nationwide\n",
      "Con: ['pilot', 'multi-', 'voucher', 'designing', 'hyper-', 'groundbreaking', 'genomes', 'outreach']\n",
      "Lab: ['clydebridge', 'wigan', 'salford', 'whiston', 'outer', 'haringey', 'edmonton', 'rotherham']\n",
      "\n",
      "presiding\n",
      "Con: ['commanding', 'certification', 'warranted', 'senior', 'chief', 'police', 'miNUMBER', 'outgoing']\n",
      "Lab: ['preside', 'presided', 'roughshod', 'glossed', 'hangs', 'presides', 'hanging', 'pored']\n",
      "\n",
      "super-\n",
      "Con: ['weston-', 'mare', 'berwick-', 'aldridge-', 'selby', 'tweed', 'upon-', 'brigg']\n",
      "Lab: ['corporations', 'rich', 'giveaways', 'wealthy', 'mega-', 'property-', 'sugary', 'basement']\n",
      "\n",
      "supposedly\n",
      "Con: ['brutally', 'uvf', 'vive', 'socialist', 'wyn', 'repressive', 'arabs', 'raping']\n",
      "Lab: ['enforceable', 'unfairly', 'obstructing', 'cheating', 'lawful', 'taxing', 'exploiting', 'device']\n",
      "\n",
      "ideally\n",
      "Con: ['marina', 'niger', 'preferably', 'chad', 'unconscionable', 'alternatively', 'expedient', 'alas']\n",
      "Lab: ['justiciable', 'clydebridge', 'disciplined', 'ordinarily', 'unthinking', 'administratively', 'bulgaria', 'lidl']\n",
      "\n",
      "alert\n",
      "Con: ['react', 'exposed', 'alerted', 'subjected', 'attuned', 'communicated', 'attributed', 'advised']\n",
      "Lab: ['adversarial', 'outright', 'overhead', 'advisable', 'overdose', 'oyster-', 'actor', 'alcoholic']\n",
      "\n",
      "like-\n",
      "Con: ['fair-', 'independent-', 'narrow-', 'laser-', 'treaty-', 'breck', 'butterfly', 'victor']\n",
      "Lab: ['laser-', 'proverbial', 'for-', 'sardines', 'caged', 'sounds', 'commission-', 'tat']\n",
      "\n",
      "simultaneously\n",
      "Con: ['monsters', 'urdu', 'crucifixions', 'intercontinental', 'currencies', 'spawning', 'pews', 'vive']\n",
      "Lab: ['bent', 'destinies', 'cronies', 'abetting', 'uprooted', 'betting', 'slashing', 'germans']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Con:\", [x[0] for x in con_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"Lab:\", [x[0] for x in lab_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EU vs Non-EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from build_features import split_corpus\n",
    "\n",
    "eu_mentions, non_eu_mentions = split_corpus(all_contributions, \"eu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# EU model\n",
    "eu_model = Word2Vec(all_toks.loc[eu_mentions.index], size=300)\n",
    "\n",
    "# Non-EU model\n",
    "neu_model = Word2Vec(all_toks.loc[non_eu_mentions.index], size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eu_ranked_words_models = get_most_changey_words_with_models(eu_model, neu_model, n=10, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'ord'),\n",
       " (3, 'sterling'),\n",
       " (7, 'entrenchment'),\n",
       " (8, 'ceta'),\n",
       " (12, 'suing'),\n",
       " (13, 'circuit'),\n",
       " (14, 'decree'),\n",
       " (14, 'formalities'),\n",
       " (15, 'eurosceptic'),\n",
       " (15, 'gras'),\n",
       " (15, 'restarted'),\n",
       " (16, 'cemented'),\n",
       " (16, 'merchants'),\n",
       " (16, 'rigidity'),\n",
       " (16, 'unskilled'),\n",
       " (17, 'busting'),\n",
       " (17, 'exiting'),\n",
       " (17, 'foie'),\n",
       " (17, 'redefining'),\n",
       " (17, 'tra')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_ranked_words_models[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_eu, vectors_eu = get_top_vocab_and_vectors(eu_model)\n",
    "vocab_neu, vectors_neu = get_top_vocab_and_vectors(neu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eu_ranked_words_vectors = get_most_changey_words_with_vectors(vocab_eu, vocab_neu, vectors_eu, vectors_neu, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(92, 'ii'),\n",
       " (150, 'master'),\n",
       " (153, 'sterling'),\n",
       " (195, 'dangerously'),\n",
       " (198, 'correcting'),\n",
       " (198, 'straightaway'),\n",
       " (200, 'prisoner'),\n",
       " (217, 'bypass'),\n",
       " (218, 'conversion'),\n",
       " (223, 'staying'),\n",
       " (225, 'naturally'),\n",
       " (225, 'relentlessly'),\n",
       " (226, 'honours'),\n",
       " (231, 'contracting'),\n",
       " (237, 'manifestly'),\n",
       " (239, 'leaving'),\n",
       " (244, 'post'),\n",
       " (244, 'timetabling'),\n",
       " (245, 'leavers'),\n",
       " (246, 'invariably')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_ranked_words_vectors[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ii',\n",
       " 'sterling',\n",
       " 'correcting',\n",
       " 'prisoner',\n",
       " 'bypass',\n",
       " 'conversion',\n",
       " 'staying',\n",
       " 'naturally',\n",
       " 'honours',\n",
       " 'contracting']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in eu_ranked_words_vectors if check_freq(w[1],eu_model) and check_freq(w[1],neu_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii\n",
      "EU : ['ii', 'regulation', 'arrest', 'information', 'directive', 'existing', 'access', '(']\n",
      "NEU: ['c', 'b', 'st', 'o', 'elizabeth', 'insert', 'king', 'victoria']\n",
      "\n",
      "sterling\n",
      "EU : ['NUMBER%', 'unemployment', 'growth', 'exports', 'pound', 'wages', 'average', 'poverty']\n",
      "NEU: ['sterling', 'pensions', 'fantastic', 'excellent', 'tireless', '(', 'sir', 'constituent']\n",
      "\n",
      "correcting\n",
      "EU : ['powers', 'viii', 'henry', 'clauses', 'bill', 'section', 'delegated', 'statutory']\n",
      "NEU: ['put', 'correct', 'telling', 'giving', 'saying', 'talking', 'told', 'struck']\n",
      "\n",
      "prisoner\n",
      "EU : ['directive', 'regulations', 'non-', 'treaty', 'sanctions', 'data', 'regulation', 'existing']\n",
      "NEU: ['officer', 'prison', 'prisoners', 'woman', 'someone', 'child', 'prisoner', 'offenders']\n",
      "\n",
      "bypass\n",
      "EU : ['provide', 'make', 'allow', 'ensure', 'avoid', 'prevent', 'establish', 'commit']\n",
      "NEU: ['aNUMBER', 'road', 'member', 'town', 'mNUMBER', 'airport', 'towns', 'roads']\n",
      "\n",
      "conversion\n",
      "EU : ['david', 'comments', 'chancellor', 'majesty', 'speech', 'sir', 'predecessor', 'st']\n",
      "NEU: ['introduction', 'extension', 'ban', 'marriage', 'conversion', 'removal', 'entry', 'sale']\n",
      "\n",
      "staying\n",
      "EU : ['leaving', 'stay', 'remaining', 'remain', 'referendum', 'leave', 'membership', 'customs']\n",
      "NEU: ['living', 'staying', 'live', 'hours', 'waiting', 'who', 'lived', 'getting']\n",
      "\n",
      "naturally\n",
      "EU : ['join', 'represent', 'small', 'liberal', 'including', 'whose', 'importantly', 'community']\n",
      "NEU: ['otherwise', 'often', 'frankly', 'sure', 'soon', 'obviously', 'naturally', 'certainly']\n",
      "\n",
      "honours\n",
      "EU : ['gave', 'delivers', 'protects', 'manifesto', 'deliver', 'led', 'provides', 'honour']\n",
      "NEU: ['queen', 'two-', 'a', 'pension', 'awards', 'award', 'awarded', 'long']\n",
      "\n",
      "contracting\n",
      "EU : ['cross-', 'all-', 'treaty', 'conservative', 'third-', 'democratic', 'labour', 'eea']\n",
      "NEU: ['roll-', 'carry', 'carrying', 'set', 'rolling', 'rolled', 'sets', 'setting']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"EU :\", neighbors(query, vectors_eu, vocab_eu, 8))\n",
    "    print(\"NEU:\", neighbors(query, vectors_neu, vocab_neu, 8))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sterling',\n",
       " 'conversion',\n",
       " 'honours',\n",
       " 'bypass',\n",
       " 'counting',\n",
       " 'naturally',\n",
       " 'en',\n",
       " 'correcting',\n",
       " 'privately',\n",
       " 'contracting']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in eu_ranked_words_models if check_freq(w[1],eu_model) and check_freq(w[1],neu_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sterling\n",
      "Con: ['devaluation', 'depreciation', 'inflation', 'pound', 'unemployment', 'earnings', 'decline', 'decrease']\n",
      "Lab: ['tireless', 'tremendous', 'preparatory', 'valiant', 'jamieson', 'steen', 'praising', 'superb']\n",
      "\n",
      "conversion\n",
      "Con: ['poem', 'julius', 'damascene', 'scarf', 'resistance', 'salt', 'cell', 'drama']\n",
      "Lab: ['removal', 'convert', 'refusal', 'residence', 'promotion', 'conversions', 'reintroduction', 'damascene']\n",
      "\n",
      "honours\n",
      "Con: ['delivers', 'honouring', 'protects', 'secures', 'maintains', 'reaffirmed', 'undermines', 'supports']\n",
      "Lab: ['bicameral', 'fixture', 'yellow', 'todger', 'eighth', 'medal', 'exhaustive', 'coveted']\n",
      "\n",
      "bypass\n",
      "Con: ['install', 'facilitate', 'fetter', 'assist', 'organise', 'constrain', 'initiate', 'hamper']\n",
      "Lab: ['aNUMBER', 'expressway', 'tunnel', 'junction', 'mNUMBER', 'redevelopment', 'depot', 'stonehenge']\n",
      "\n",
      "counting\n",
      "Con: ['overlooking', 'footway', 'breeding', 'squeezing', 'pavements', 'assembled', 'freezing', 'lecturers']\n",
      "Lab: ['spads', 'whammy', 'languishing', 'pacifists', 'electromagnetic', 'absconding', 'rails', 'cardboard']\n",
      "\n",
      "naturally\n",
      "Con: ['newer', 'narrow-', 'fair-', 'heriot-', 'inventors', 'beef', 'devastate', 'upland']\n",
      "Lab: ['understandably', 'obviously', 'inevitably', 'usually', 'frankly', 'otherwise', 'normally', 'ideally']\n",
      "\n",
      "en\n",
      "Con: ['g', 'stringer', 'griffith', 'victoria', 'brabin', 'andrea', 'afolami', 'brock']\n",
      "Lab: ['compton', 'arterial', 'wessex', 'paddington', 'menin', 'mainline', 'depot', 'electrify']\n",
      "\n",
      "correcting\n",
      "Con: ['sweeping', 'viii', 'henry', 'delegated', 'investigatory', 'conferring', 'drafting', 'disapply']\n",
      "Lab: ['repeating', 'unblemished', 'woeful', 'correct', 'clarifying', 'corrects', 'lows', 'corrected']\n",
      "\n",
      "privately\n",
      "Con: ['publicly', 'wrongly', 'grey-', 'remoaners', 'breeders', 'aileen', 'allard', 'michael']\n",
      "Lab: ['council-', 'wholly-', 'owner-', 'foreign-', 'publicly', 'centrally', 'freehold', 'employee-']\n",
      "\n",
      "contracting\n",
      "Con: ['third-', 'transcends', 'interpretative', 'communist', 'republican', 'governing', 'political', 'socialist']\n",
      "Lab: ['phasing', 'kilter', 'sorting', 'bail-', 'contracted-', 'opting', 'opt-', 'bailing']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Con:\", [x[0] for x in eu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"Lab:\", [x[0] for x in neu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remainers vs Leavers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "remain = all_contributions.query(\"ref_stance == 'remain'\")\n",
    "leave = all_contributions.query(\"ref_stance == 'leave'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# remain model\n",
    "rem_model = Word2Vec(all_toks.loc[remain.index], size=300)\n",
    "\n",
    "# leave model\n",
    "lea_model = Word2Vec(all_toks.loc[leave.index], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_rem, vectors_rem = get_top_vocab_and_vectors(rem_model)\n",
    "vocab_lea, vectors_lea = get_top_vocab_and_vectors(lea_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem_lea_ranked_words_vectors = get_most_changey_words_with_vectors(vocab_rem, vocab_lea, vectors_rem, vectors_lea, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(166, 'duck'),\n",
       " (175, 'acknowledging'),\n",
       " (229, 'dodgy'),\n",
       " (240, 'rotten'),\n",
       " (257, 'gamble'),\n",
       " (260, 'bells'),\n",
       " (260, 'fixing'),\n",
       " (260, 'useless'),\n",
       " (262, 'reigate'),\n",
       " (270, 'anymore'),\n",
       " (270, 'recalled'),\n",
       " (271, 'mirrors'),\n",
       " (271, 'supposedly'),\n",
       " (272, 'wash'),\n",
       " (283, 'anticipation'),\n",
       " (285, 'relentlessly'),\n",
       " (286, 'meanwhile'),\n",
       " (290, 'ii'),\n",
       " (291, 'remotely'),\n",
       " (303, 'decisively')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_lea_ranked_words_vectors[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['supposedly',\n",
       " 'ii',\n",
       " 'fareham',\n",
       " 'plots',\n",
       " 'google',\n",
       " 'eastleigh',\n",
       " 'crawley',\n",
       " 'halt',\n",
       " 'typical',\n",
       " 'display']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq = 50\n",
    "check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "queries = [w[1] for w in rem_lea_ranked_words_vectors if check_freq(w[1],rem_model) and check_freq(w[1],lea_model)]\n",
    "queries = queries[:10]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supposedly\n",
      "Remain: ['plotting', 'routinely', 'barbarians', 'shredded', 'abusing', 'sued', 'investigating', 'brutally']\n",
      "Leaver: ['defending', 'enforceable', 'bureaucrats', 'legally', 'asserting', 'cheating', 'attacking', 'essentially']\n",
      "\n",
      "ii\n",
      "Remain: ['ecris', 'database', 'ec', 'prisoner', 'sharing', 'europol', 'NUMBERc', 'eurojust']\n",
      "Leaver: ['mckinnell', 'ag', 'girvan', 'bellingham', 'frith', 'beckett', 'k', 'g']\n",
      "\n",
      "fareham\n",
      "Remain: ['kirkcaldy', 'spelthorne', 'gedling', 'cowdenbeath', 'braintree', 'dwyfor', 'stalybridge', 'streatham']\n",
      "Leaver: ['dewsbury', 'crawley', 'neath', 'eastleigh', 'chippenham', 'cheadle', 'newark', 'chichester']\n",
      "\n",
      "plots\n",
      "Remain: ['radicalism', 'kovtun', 'fgm', 'rapes', 'boko', 'islamism', 'sexually', 'preachers']\n",
      "Leaver: ['attacks', 'murders', 'foiled', 'missiles', 'rockets', 'incidents', 'atrocities', 'sympathisers']\n",
      "\n",
      "google\n",
      "Remain: ['facebook', 'twitter', 'auschwitz', 'amazon', 'apple', 'asda', 'passchendaele', 'injuries']\n",
      "Leaver: ['facebook', 'apple', 'amazon', 'twitter', 'microsoft', 'ebay', 'youtube', 'multinational']\n",
      "\n",
      "eastleigh\n",
      "Remain: ['spelthorne', 'mims', 'eltham', 'rothwell', 'cowdenbeath', 'wishaw', 'beckenham', 'devizes']\n",
      "Leaver: ['chippenham', 'cheadle', 'ogmore', 'fareham', 'romford', 'aldershot', 'burnley', 'solihull']\n",
      "\n",
      "crawley\n",
      "Remain: ['bradley', 'bellingham', 'keegan', 'thangam', 'newbury', 'thomas-', 'priti', 'wes']\n",
      "Leaver: ['fareham', 'dewsbury', 'romford', 'chippenham', 'lincoln', 'newton', 'cheadle', 'norwich']\n",
      "\n",
      "halt\n",
      "Remain: ['grind', 'block', 'sledgehammer', 'avert', 'reverse', 'gym', 'eliminate', 'rethink']\n",
      "Leaver: ['ditch', 'abandon', 'scrap', 'rethink', 'avert', 'reverse', 'stop', 'cancel']\n",
      "\n",
      "typical\n",
      "Remain: ['abysmal', 'commendable', 'pathetic', 'revelation', 'dismal', 'stunning', 'trustee', 'symptomatic']\n",
      "Leaver: ['staggering', 'median', 'basic-', 'earns', 'pint', 'NUMBERp', 'tiny', 'average']\n",
      "\n",
      "display\n",
      "Remain: ['pictures', 'shoulders', 'television', 'beach', 'youtube', 'throne', 'arrival', 'lips']\n",
      "Leaver: ['displaying', 'displays', 'wearing', 'displayed', 'wear', 'outpouring', 'enjoyment', 'camera']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(\"Remain:\", [x[0] for x in eu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"Leaver:\", [x[0] for x in neu_model.wv.most_similar(query, topn=8)])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_models = dict()\n",
    "# Train a language model for various different portions of the forum.\n",
    "for w, w_posts in get_time_windows(all_contributions, 365, 365, time_column=\"date\"):\n",
    "    time_models[w] = Word2Vec(all_toks.loc[w_posts.index], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_over_time(search_term, time_models, top_n=10000):\n",
    "    for window, curr_model in time_models.items():\n",
    "        curr_vocab, curr_vectors = get_top_vocab_and_vectors(curr_model, top_n)\n",
    "        print(window)\n",
    "        if search_term in curr_vocab:\n",
    "            print(neighbors(search_term, curr_vectors, curr_vocab, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['stay', 'go', 'vote', 'lose', 'come', 'be', 'remain', 'take', 'get', 'move', 'tell', 'give']\n",
      "2016-05-17 00:00:00\n",
      "['referendum', 'remain', 'brexit', 'leaving', 'stay', 'left', 'lose', 'go', 'exit', 'vote', 'get', 'come']\n",
      "2017-05-17 00:00:00\n",
      "['referendum', 'exit', 'leaving', 'left', 'remain', 'vote', 'stay', 'lose', 'look', 'voted', 'move', 'get']\n",
      "2018-05-17 00:00:00\n",
      "['referendum', 'remain', 'leaving', 'stay', 'vote', 'left', 'get', 'go', 'exit', 'lose', 'brexit', 'deal']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"leave\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['every', 'one', 'one-', 'two-', 'union', 'free', 'parent', 'largest', 'third', 'each', 'child', 'person']\n",
      "2016-05-17 00:00:00\n",
      "['union', 'eu', 'european', 'labour', 'market', 'customs', 'every', 'common', 'vote', 'leave', 'one', 'an']\n",
      "2017-05-17 00:00:00\n",
      "['union', 'customs', 'labour', 'common', 'eu', 'euratom', 'eea', 'internal', 'one', 'vote', 'free', 'an']\n",
      "2018-05-17 00:00:00\n",
      "['common', 'customs', 'every', 'union', 'eu', 'one', 'labour', 'rule', 'an', 'market', 'any', 'free']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"single\", time_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get examples for chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours_over_time_comma_delimited(query, time_models, top_n=10000):\n",
    "    for window, curr_model in time_models.items():\n",
    "        curr_vocab, curr_vectors = get_top_vocab_and_vectors(curr_model, top_n)\n",
    "        if query in curr_vocab:\n",
    "            print(window.strftime(\"%y/%m/%d\"), end=\",\")\n",
    "            print(\",\".join(neighbors(query, curr_vectors, curr_vocab, 6)))\n",
    "        else:\n",
    "            print(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brexit\n",
      "15/05/18,eu,vote,leave,european,election,union\n",
      "16/05/17,referendum,eu,negotiations,leave,trade,vote\n",
      "17/05/17,exit,eu,trade,referendum,union,negotiations\n",
      "18/05/17,deal,referendum,vote,backstop,prime,trade\n",
      "\n",
      "referendum\n",
      "15/05/18,election,vote,elections,debate,parliament,period\n",
      "16/05/17,vote,election,brexit,leave,voted,parliament\n",
      "17/05/17,election,vote,leave,voted,brexit,negotiations\n",
      "18/05/17,vote,election,brexit,voted,leave,article\n",
      "\n",
      "immigration\n",
      "15/05/18,welfare,criminal,justice,migration,sanctions,asylum\n",
      "16/05/17,foreign,eu,prime,brexit,movement,trade\n",
      "17/05/17,trade,eu,tax,legal,customs,foreign\n",
      "18/05/17,trade,justice,fisheries,migration,tax,eu\n",
      "\n",
      "single\n",
      "15/05/18,every,one,one-,two-,union,free\n",
      "16/05/17,union,eu,european,labour,market,customs\n",
      "17/05/17,union,customs,labour,common,eu,euratom\n",
      "18/05/17,common,customs,every,union,eu,one\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in [\"brexit\", \"referendum\", \"immigration\", \"single\"]:\n",
    "    print(query)\n",
    "    neighbours_over_time_comma_delimited(query, time_models)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changiest words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_changiest_words_per_window(time_models, top_n=10000, k=1000):\n",
    "    out_dic = dict()\n",
    "    windows = list(time_models.keys())\n",
    "    for i in range(1, len(windows)):\n",
    "        model_1 = time_models[windows[i-1]]\n",
    "        model_2 = time_models[windows[i]]\n",
    "\n",
    "        vocab_1, vectors_1 = get_top_vocab_and_vectors(model_1, top_n)\n",
    "        vocab_2, vectors_2 = get_top_vocab_and_vectors(model_2, top_n)\n",
    "\n",
    "        out_dic[windows[i]] = get_most_changey_words_with_vectors(vocab_1, vocab_2, vectors_1, vectors_2, k=k)\n",
    "\n",
    "    return out_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "changiest_words_per_window = get_changiest_words_per_window(time_models, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_changiest_over_time(changiest_words_per_window, min_freq=0):\n",
    "    for window, changey_words in changiest_words_per_window.items():\n",
    "        check_freq = lambda w, m: m.wv.vocab[w].count > min_freq\n",
    "        queries = [w[1] for w in changey_words if check_freq(w[1],model)]\n",
    "        queries = queries[:20]\n",
    "\n",
    "        print(window)\n",
    "#         t20_words = [f\"{w[1]} {w[0]}\" for w in changey_words[:20]]\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[:5]))\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[5:10]))\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[10:15]))\n",
    "        print(\"{:20} {:20} {:20} {:20} {:20}\".format(*queries[15:20]))\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "google               dog                  customs              style                similarly           \n",
      "plain                bomb                 e-                   strikes              rbs                 \n",
      "tv                   managing             exit                 grammar              independently       \n",
      "trading              supreme              s.                   brexit               smith               \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "retained             osborne              selection            tower                super-              \n",
      "principal            no-                  salisbury            radio                bbc                 \n",
      "shipley              similarly            privatisation        wear                 s.                  \n",
      "leigh                chemical             philip               semitism             continually         \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "offensive            grieve               permanent            charter              moreover            \n",
      "bone                 principal            zero                 and-                 white               \n",
      "basically            virtually            letwin               overnight            card                \n",
      "mixed                no-                  presumably           furthermore          meanwhile           \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['gas', 'revenue', 'customs', 'trade', 'oil', 'energy', 'taxpayers', 'intelligence', 'insert', 'reduce', 'department', 'billion']\n",
      "2016-05-17 00:00:00\n",
      "['customs', 'eu', 'trade', 'market', 'europe', 'credit', 'movement', 'national', 'single', 'trading', 'membership', 'tax']\n",
      "2017-05-17 00:00:00\n",
      "['european', 'trade', 'eu', 'border', 'euratom', 'market', 'brexit', 'credit', 'regulatory', 'eea', 'transitional', 'withdrawal']\n",
      "2018-05-17 00:00:00\n",
      "['european', 'backstop', 'deal', 'trade', 'agreement', 'eu', 'border', 'market', 'regulatory', 'relationship', 'arrangement', 'article']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"customs\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['eu', 'vote', 'leave', 'european', 'election', 'union', 'membership', 'stay', 'europe', 'president', 'campaign', 'leader']\n",
      "2016-05-17 00:00:00\n",
      "['referendum', 'eu', 'negotiations', 'leave', 'trade', 'vote', 'exit', 'what', 'article', 'uncertainty', 'union', 'state']\n",
      "2017-05-17 00:00:00\n",
      "['exit', 'eu', 'trade', 'referendum', 'union', 'negotiations', 'border', 'vote', 'deal', 'transition', 'customs', 'foreign']\n",
      "2018-05-17 00:00:00\n",
      "['deal', 'referendum', 'vote', 'backstop', 'prime', 'trade', 'exit', 'union', 'eu', 'leave', 'border', 'state']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"brexit\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['carbon', 'rate', 'emissions', 'lower', 'zero', 'gdp', 'deficit', 'higher', 'reduction', 'growth', 'low', 'price']\n",
      "2016-05-17 00:00:00\n",
      "['rate', 'higher', 'income', 'lower', 'rates', 'low', '', 'average', 'gdp', 'prices', 'price', 'increase']\n",
      "2017-05-17 00:00:00\n",
      "['', 'rate', 'average', 'zero', 'rates', 'lower', 'growth', 'NUMBER', 'tariffs', 'income', 'homes', 'billion']\n",
      "2018-05-17 00:00:00\n",
      "['carbon', 'emissions', 'NUMBER%', 'reduce', 'net', 'growth', 'gdp', 'tariffs', 'global', 'rate', 'low', 'gas']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"zero\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['st', 'south', 'royal', 'city', '(', 'borough', 'towns', 'park', 'station', 'glasgow', 'street', 'county']\n",
      "2016-05-17 00:00:00\n",
      "['(', 'st', 'hospital', 'royal', 'city', 'borough', 'centre', 'college', 'constituency', 'county', 'park', 'station']\n",
      "2017-05-17 00:00:00\n",
      "['grenfell', 'blocks', 'fire', 'homes', 'cladding', 'accommodation', 'tragedy', 'residents', 'happened', 'buildings', 'safety', 'hospital']\n",
      "2018-05-17 00:00:00\n",
      "['tower', 'hospital', 'died', 'london', 'street', 'constituency', 'fire', 'grenfell', 'visited', 'park', 'station', 'st']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"tower\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['benefit', 'pension', 'overseas', 'income', 'payment', 'annual', 'payments', 'compensation', 'licence', 'receive', 'exemption', 'taxpayer']\n",
      "2016-05-17 00:00:00\n",
      "['negotiations', 'brexit', 'article', 'leave', 'referendum', 'eu', 'agreement', 'withdrawal', 'membership', 'leaving', 'departure', 'negotiating']\n",
      "2017-05-17 00:00:00\n",
      "['withdrawal', 'brexit', 'eu', 'leave', 'law', 'negotiations', 'implementation', 'transition', 'statute', 'referendum', 'agreement', 'legislation']\n",
      "2018-05-17 00:00:00\n",
      "['brexit', 'leave', 'leaving', 'article', 'withdrawal', 'eu', 'departure', 'referendum', 'relationship', 'deal', 'extension', 'negotiations']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"exit\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['nuclear', 'air', 'where', 'anywhere', 'no-', 'terrorist', 'towards', 'assad', 'isil', 'without', 't', 'beyond']\n",
      "2016-05-17 00:00:00\n",
      "['nuclear', 'or', 'zone', 'create', 'fly', 'weapons', 'competitive', 'where', 'car', 'uk-', 'property', 'two-']\n",
      "2017-05-17 00:00:00\n",
      "['brexit', 'transitional', 'trade', 'no', 'great', 'transition', 'bad', 'without', 'with', 'border', 'cliff', 'withdrawal']\n",
      "2018-05-17 00:00:00\n",
      "['no', 'without', 'bad', 'negotiated', 'great', 'scenario', 'any', 'post-', 'brexit', 'chequers', 'vote', 'contingency']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"no-\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-05-18 00:00:00\n",
      "['foreign', 'home', 'permanent', 'cabinet', 'defence', 'chief', 'financial', 'private', 'states', 'former', 'justice', 'exchequer']\n",
      "2016-05-17 00:00:00\n",
      "['home', 'state', 'permanent', 'cabinet', 'defence', 'financial', 'states', 'chief', 'private', 'justice', 'former', 'rights']\n",
      "2017-05-17 00:00:00\n",
      "['home', 'state', 'foreign', 'cabinet', 'accommodation', 'private', 'environment', 'homes', 'chief', 'temporary', 'financial', 'housing']\n",
      "2018-05-17 00:00:00\n",
      "['state', 'permanent', 'home', 'cabinet', 'customs', 'defence', 'transport', 'environment', 'chief', 'trade', 'brexit', 'general']\n"
     ]
    }
   ],
   "source": [
    "neighbours_over_time(\"permanent\", time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brexit\n",
      "15/05/18,eu,vote,leave,european,election,union\n",
      "16/05/17,referendum,eu,negotiations,leave,trade,vote\n",
      "17/05/17,exit,eu,trade,referendum,union,negotiations\n",
      "18/05/17,deal,referendum,vote,backstop,prime,trade\n",
      "\n",
      "customs\n",
      "15/05/18,gas,revenue,customs,trade,oil,energy\n",
      "16/05/17,customs,eu,trade,market,europe,credit\n",
      "17/05/17,european,trade,eu,border,euratom,market\n",
      "18/05/17,european,backstop,deal,trade,agreement,eu\n",
      "\n",
      "strike\n",
      "15/05/18,take,taken,vote,thing,industrial,action\n",
      "16/05/17,strike,get,carry,be,hold,taken\n",
      "17/05/17,take,get,strike,give,be,carry\n",
      "18/05/17,negotiate,be,get,take,reach,create\n",
      "\n",
      "tower\n",
      "15/05/18,st,south,royal,city,(,borough\n",
      "16/05/17,(,st,hospital,royal,city,borough\n",
      "17/05/17,grenfell,blocks,fire,homes,cladding,accommodation\n",
      "18/05/17,tower,hospital,died,london,street,constituency\n",
      "\n",
      "salisbury\n",
      "15/05/18,royal,tribute,st,john,james,town\n",
      "16/05/17,hon,south,north,east,states,west\n",
      "17/05/17,grenfell,war,attack,syria,events,terrorist\n",
      "18/05/17,killed,war,attacks,died,events,syria\n",
      "\n",
      "no-\n",
      "15/05/18,nuclear,air,where,anywhere,no-,terrorist\n",
      "16/05/17,nuclear,or,zone,create,fly,weapons\n",
      "17/05/17,brexit,transitional,trade,no,great,transition\n",
      "18/05/17,no,without,bad,negotiated,great,scenario\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in [\"brexit\", \"customs\", \"strike\", \"tower\", \"salisbury\", \"no-\"]:\n",
    "    print(query)\n",
    "    neighbours_over_time_comma_delimited(query, time_models)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changiest Words Conservative vs Labour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "con_time_models = dict()\n",
    "lab_time_models = dict()\n",
    "# Train a language model for various different portions of the forum.\n",
    "for w, w_posts in get_time_windows(all_contributions, 365, 365, time_column=\"date\"):\n",
    "    curr_con = w_posts[w_posts.index.isin(conservatives.index)].index\n",
    "    curr_lab = w_posts[w_posts.index.isin(labour.index)].index\n",
    "    \n",
    "    con_time_models[w] = Word2Vec(all_toks.loc[curr_con], size=300)\n",
    "    lab_time_models[w] = Word2Vec(all_toks.loc[curr_lab], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "con_changiest_words_per_window = get_changiest_words_per_window(con_time_models, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "selection            dual                 upper                customs              reflecting          \n",
      "google               english              blue                 purely               red                 \n",
      "presumably           typical              strikes              similarly            precious            \n",
      "stark                moreover             green                exit                 regards             \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "style                selection            henry                chaos                thereafter          \n",
      "retained             hopes                naturally            moreover             bearing             \n",
      "shock                text                 no-                  leasehold            inadvertently       \n",
      "journalists          separately           precious             ends                 merit               \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "e-                   forever              charter              fresh                essentially         \n",
      "grieve               similarly            magistrates          nerve                calm                \n",
      "bearing              beat                 facebook             progressive          latter              \n",
      "naturally            windrush             merit                abortion             henry               \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(con_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_neighours(query):\n",
    "    print(\"Conservative\")\n",
    "    neighbours_over_time(query, con_time_models)\n",
    "    print(\"\\nLabour\")\n",
    "    neighbours_over_time(query, lab_time_models)\n",
    "    \n",
    "def compare_neighours_comma_delimited(query):\n",
    "    print(\"Conservative\")\n",
    "    neighbours_over_time_comma_delimited(query, con_time_models)\n",
    "    print(\"\\nLabour\")\n",
    "    neighbours_over_time_comma_delimited(query, lab_time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,iraq,isil,daesh,war,conflict,threat\n",
      "16/05/17,happened,war,weapons,ago,east,arabia\n",
      "17/05/17,no,court,system,risk,regime,pension\n",
      "18/05/17,deal,border,referendum,brexit,backstop,risk\n",
      "\n",
      "Labour\n",
      "15/05/18,department,crisis,spending,impact,office,recent\n",
      "16/05/17,country,world,investment,funding,past,budget\n",
      "17/05/17,debate,policy,budget,NUMBER%,question,problem\n",
      "18/05/17,deal,austerity,brexit,crisis,economy,world\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"chaos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,terrorist,into,daesh,air,isil,global\n",
      "16/05/17,nuclear,parking,property,trade,car,&\n",
      "17/05/17,trade,no,customs,without,long-,brexit\n",
      "18/05/17,no,without,with,great,negotiated,brexit\n",
      "\n",
      "Labour\n",
      "15/05/18,such,between,free,low-,against,high-\n",
      "16/05/17,&,free,long-,low-,year-,between\n",
      "17/05/17,with,transitional,brexit,no,deal,agreement\n",
      "18/05/17,no,brexit,without,trade,any,vote\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"no-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,tax,european,majesty,trade,taxpayers,billion\n",
      "16/05/17,customs,eu,trade,europe,national,single\n",
      "17/05/17,european,eu,trade,europe,market,withdrawal\n",
      "18/05/17,european,eu,backstop,trade,deal,agreement\n",
      "\n",
      "Labour\n",
      "15/05/18,majesty,,allowance,cut,department,green\n",
      "16/05/17,eu,trade,customs,market,union,national\n",
      "17/05/17,european,trade,eu,market,agreement,brexit\n",
      "18/05/17,european,trade,eu,agreement,deal,market\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"customs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,income,eu,rate,insurance,,exit\n",
      "16/05/17,eu,negotiations,brexit,european,agreement,leave\n",
      "17/05/17,eu,withdrawal,leave,negotiations,law,brexit\n",
      "18/05/17,leave,eu,deal,period,leaving,article\n",
      "\n",
      "Labour\n",
      "15/05/18,income,impact,,increase,tax,NUMBER%\n",
      "16/05/17,european,trade,market,union,brexit,agreement\n",
      "17/05/17,eu,period,agreement,brexit,day,european\n",
      "18/05/17,eu,withdrawal,article,exit,trade,customs\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lab_changiest_words_per_window = get_changiest_words_per_window(lab_time_models, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "managing             irresponsible        stem                 half-                differently         \n",
      "rarely               breaking             firmly               dog                  presumably          \n",
      "definitely           detention            court                constant             fashion             \n",
      "loophole             empty                bold                 english              assad               \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "presumably           bbc                  selection            basically            differently         \n",
      "promising            worthy               content              continually          fashion             \n",
      "backwards            approaching          dreadful             normal               retained            \n",
      "binding              witness              no-                  russians             donations           \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "politically          agent                exact                preferred            penalty             \n",
      "diminished           firmly               offensive            collectively         by-                 \n",
      "principal            apparent             renewal              accepting            bone                \n",
      "zero                 realistic            presumably           far-                 cruel               \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(lab_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,united,sovereign,play,european,democratic,proud\n",
      "16/05/17,european,sovereign,pension,vote,against,member\n",
      "17/05/17,global,nuclear,member,european,nation,eu\n",
      "18/05/17,european,law,customs,control,democratic,nation\n",
      "\n",
      "Labour\n",
      "15/05/18,member,leader,united,affairs,office,european\n",
      "16/05/17,united,vote,members,leader,referendum,this\n",
      "17/05/17,our,security,democracy,must,international,armed\n",
      "18/05/17,united,member,parliament,party,british,scottish\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"sovereign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,rights,sovereignty,membership,nation,members,interests\n",
      "16/05/17,party,referendum,parliament,vote,democracy,sovereignty\n",
      "17/05/17,parliament,democracy,law,membership,rights,sovereignty\n",
      "18/05/17,interests,democracy,rights,referendum,voted,vote\n",
      "\n",
      "Labour\n",
      "15/05/18,eu,party,united,role,european,membership\n",
      "16/05/17,debate,leader,parliament,party,secretary,house\n",
      "17/05/17,debate,democracy,committee,parliament,membership,role\n",
      "18/05/17,agreement,economy,country,parliament,future,democracy\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"sovereignty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conservative\n",
      "15/05/18,,NUMBER%,mr,madam,referendum,insert\n",
      "16/05/17,eu,referendum,negotiations,union,trade,european\n",
      "17/05/17,eu,agreement,trade,negotiations,exit,period\n",
      "18/05/17,deal,referendum,vote,backstop,us,agreement\n",
      "\n",
      "Labour\n",
      "15/05/18,united,page,european,amendment,election,vote\n",
      "16/05/17,eu,referendum,us,european,vote,trade\n",
      "17/05/17,trade,state,foreign,eu,customs,deal\n",
      "18/05/17,deal,vote,state,prime,trade,eu\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"brexit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changiest Words Remain vs Leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem_time_models = dict()\n",
    "lea_time_models = dict()\n",
    "# Train a language model for various different portions of the forum.\n",
    "for w, w_posts in get_time_windows(all_contributions, 365, 365, time_column=\"date\"):\n",
    "    curr_rem = w_posts[w_posts.index.isin(remain.index)].index\n",
    "    curr_lea = w_posts[w_posts.index.isin(leave.index)].index\n",
    "    \n",
    "    rem_time_models[w] = Word2Vec(all_toks.loc[curr_rem], size=300)\n",
    "    lea_time_models[w] = Word2Vec(all_toks.loc[curr_lea], size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_neighours(query):\n",
    "    print(\"Remain\")\n",
    "    neighbours_over_time(query, rem_time_models)\n",
    "    print(\"\\nLeave\")\n",
    "    neighbours_over_time(query, lea_time_models)\n",
    "    \n",
    "def compare_neighours_comma_delimited(query):\n",
    "    print(\"Remain\")\n",
    "    neighbours_over_time_comma_delimited(query, rem_time_models)\n",
    "    print(\"\\nLeave\")\n",
    "    neighbours_over_time_comma_delimited(query, lea_time_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem_changiest_words_per_window = get_changiest_words_per_window(rem_time_models, 5000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "cell                 clubs                e-                   essentially          exit                \n",
      "facility             flooding             flow                 for-                 gift                \n",
      "guaranteed           hub                  integration          managing             nationally          \n",
      "no-                  parental             permitted            plain                pockets             \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "al-                  appointments         awards               books                cards               \n",
      "channel              childhood            cold                 collectively         cycle               \n",
      "diesel               facebook             financing            fresh                functioning         \n",
      "medicines            no-                  pathway              precious             prejudice           \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "adding               appeals              attached             attempted            beneficial          \n",
      "c                    card                 cladding             constitution         continually         \n",
      "continuation         distance             donation             downing              eu-                 \n",
      "foster               globally             historic             identifying          independently       \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(rem_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lea_changiest_words_per_window = get_changiest_words_per_window(lea_time_models, 5000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-17 00:00:00\n",
      "claimant             naturally            elect                progressive          barnett             \n",
      "bold                 explaining           highlighting         lock                 broadly             \n",
      "orders               attempts             customs              inappropriate        polish              \n",
      "re-                  settled              cards                command              platform            \n",
      "-----------------------------\n",
      "2017-05-17 00:00:00\n",
      "restoration          hopefully            challenged           limitations          spot                \n",
      "definitely           limits               retained             returns              compelling          \n",
      "explaining           taught               block                explicit             formal              \n",
      "formed               legacy               pride                references           substance           \n",
      "-----------------------------\n",
      "2018-05-17 00:00:00\n",
      "temporary            forecasts            breaks               false                agreeing            \n",
      "turkish              challenged           inevitable           returns              tie                 \n",
      "freeze               weight               content              platform             rubbish             \n",
      "count                grasp                pattern              preferred            stuck               \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print_changiest_over_time(lea_changiest_words_per_window, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain\n",
      "15/05/18,devolved,member,secretary,democratic,european,united\n",
      "16/05/17,democratic,united,leader,democracy,sovereign,vote\n",
      "17/05/17,european,nuclear,nation,democratic,democracy,role\n",
      "18/05/17,nation,independent,european,democratic,british,democracy\n",
      "\n",
      "Leave\n",
      "15/05/18,european,rights,eu,our,nation,protect\n",
      "16/05/17,british,european,member,leader,kingdom,leave\n",
      "17/05/17,(,european,customs,international,rights,united\n",
      "18/05/17,customs,eu,united,law,independent,citizens\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"sovereign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain\n",
      "15/05/18,problem,deficit,step,situation,budget,point\n",
      "16/05/17,country,point,thing,step,situation,economy\n",
      "17/05/17,step,situation,problem,crisis,position,mess\n",
      "18/05/17,country,situation,deal,crisis,position,point\n",
      "\n",
      "Leave\n",
      "15/05/18,set,NUMBER%,labour,year,carried,tax\n",
      "16/05/17,set,),,point,pointed,carried\n",
      "17/05/17,country,money,way,year,legislation,period\n",
      "18/05/17,),mr,point,sir,being,were\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"mess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain\n",
      "15/05/18,political,positive,common,democratic,cross-,effective\n",
      "16/05/17,strong,modern,sustainable,global,important,positive\n",
      "17/05/17,long-,low,tax,different,strong,common\n",
      "18/05/17,customs,sustainable,co-,trade,common,based\n",
      "\n",
      "Leave\n",
      "15/05/18,dealing,working,mental,relationship,compared,million\n",
      "16/05/17,,s,all-,long-,its,national\n",
      "17/05/17,s,),withdrawal,member,rights,union\n",
      "18/05/17,withdrawal,long-,term,co-,(,economic\n"
     ]
    }
   ],
   "source": [
    "compare_neighours_comma_delimited(\"progressive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hansard",
   "language": "python",
   "name": "hansard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
