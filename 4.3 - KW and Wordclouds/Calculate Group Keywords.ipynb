{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "sys.path.insert(1, \"../utilities\")\n",
    "from helper_functions import get_static_kws\n",
    "from settings import DB_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_all_posts =\"\"\"\n",
    "SELECT c.uid, m.name, p.party, d.date, c.body, c.topic, c.section, s.tmay_deal, s.benn_act, s.ref_stance, s.constituency_leave\n",
    "FROM contributions as c\n",
    "INNER JOIN members as m\n",
    "ON m.PimsId = c.member\n",
    "INNER JOIN debates as d\n",
    "ON d.uid = c.debate\n",
    "INNER JOIN member_party as p\n",
    "ON p.PimsId = m.PimsId\n",
    "INNER JOIN member_stances as s\n",
    "ON s.PimsId = m.PimsId\n",
    "WHERE (d.date BETWEEN date(\"2015-05-01\") AND date(\"2019-09-10\"))\n",
    "AND (((d.date BETWEEN p.start AND p.end) AND NOT (p.end IS NULL))\n",
    "OR ((d.date >= p.start) AND (p.end IS NULL)));\"\"\".strip()\n",
    "\n",
    "# regex for identifying EU/brexit mentions\n",
    "eu_regex = r'\\b(EU|[Ee]uropean [Uu]nion|[Bb]rexit)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_FP)\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Gets all the contributions and creates a nice dataframe\n",
    "all_contributions = pd.read_sql_query(sql_get_all_posts, conn)\n",
    "all_contributions.columns = ['uid', 'name', 'party', 'date', 'text', 'topic', 'section', 'tmay_deal', 'benn_act', 'ref_stance', 'constituency_leave']\n",
    "all_contributions.set_index(\"uid\", inplace=True)\n",
    "convert_to_date = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "all_contributions['date'] = all_contributions['date'].apply(convert_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from language_change_methods.utility_functions import clean_text, spacy_tokenise\n",
    "# from text_processing import ucrel_tokenise\n",
    "import nltk\n",
    "import regex as re    \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', parser=False, entity=False, matcher=False, add_vectors=False)\n",
    "\n",
    "def tokenise(text):\n",
    "    cleaned = clean_text(text)\n",
    "    cleaned = re.sub(r\"(\\p{P})\\p{P}*\", r\"\\1 \", cleaned)\n",
    "    tokens = spacy_tokenise(cleaned)\n",
    "    return tokens\n",
    "\n",
    "all_toks =  all_contributions[\"text\"].apply(tokenise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_change_methods.utility_functions import merge_lists\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tok_counter = Counter(merge_lists(all_toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import helper_functions\n",
    "reload(helper_functions)\n",
    "from helper_functions import get_static_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINDING KEYWORDS\n",
      "=======================================\n",
      "STARTED PROCESSING GROUP con-leave-mp-leave\n",
      "=======================================\n",
      "=======================================\n",
      "STARTED PROCESSING GROUP con-leave-mp-remain\n",
      "=======================================\n",
      "=======================================\n",
      "STARTED PROCESSING GROUP con-remain-mp-leave\n",
      "=======================================\n",
      "=======================================\n",
      "STARTED PROCESSING GROUP con-remain-mp-remain\n",
      "=======================================\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kws = get_static_kws(all_contributions, tok_counter, all_toks, group_type=\"brexit_stance_mp_and_constituency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../resources/group-kw-static.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({gname: kws[gname].to_dict() for gname in kws}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_language_change",
   "language": "python",
   "name": "thesis_language_change"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
